{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "train_dir = '../train'\n",
    "validation_dir = '../validation'\n",
    "test_dir = '../test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:03:28.365016: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Train dataset parts sizes: [312, 312, 312, 312]\n",
      "Validation dataset parts sizes: [78, 78, 78, 78]\n",
      "Test dataset parts sizes: [78, 78, 78, 78]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import image_dataset_from_directory\n",
    "\n",
    "IMG_SIZE = 150\n",
    "\n",
    "train_dataset = image_dataset_from_directory(train_dir, label_mode='categorical', image_size=(IMG_SIZE, IMG_SIZE))\n",
    "validation_dataset = image_dataset_from_directory(validation_dir, label_mode='categorical', image_size=(IMG_SIZE, IMG_SIZE))\n",
    "test_dataset = image_dataset_from_directory(test_dir, label_mode='categorical', image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "# Function to get the size of a dataset\n",
    "def get_dataset_size(dataset):\n",
    "    return sum(1 for _ in dataset)\n",
    "\n",
    "# Calculate the original sizes of the datasets\n",
    "train_size = get_dataset_size(train_dataset)\n",
    "validation_size = get_dataset_size(validation_dataset)\n",
    "test_size = get_dataset_size(test_dataset)\n",
    "\n",
    "# Calculate the size of each part\n",
    "part_train_size = train_size // 4\n",
    "part_validation_size = validation_size // 4\n",
    "part_test_size = test_size // 4\n",
    "\n",
    "# Function to create subsets of the datasets\n",
    "def split_dataset(dataset, part_size):\n",
    "    parts = []\n",
    "    for i in range(4):\n",
    "        parts.append(dataset.skip(i * part_size).take(part_size))\n",
    "    return parts\n",
    "\n",
    "# Create the subsets for each dataset\n",
    "train_parts = split_dataset(train_dataset, part_train_size)\n",
    "validation_parts = split_dataset(validation_dataset, part_validation_size)\n",
    "test_parts = split_dataset(test_dataset, part_test_size)\n",
    "\n",
    "# Assign the subsets to separate variables\n",
    "train_dataset_1, train_dataset_2, train_dataset_3, train_dataset_4 = train_parts\n",
    "validation_dataset_1, validation_dataset_2, validation_dataset_3, validation_dataset_4 = validation_parts\n",
    "test_dataset_1, test_dataset_2, test_dataset_3, test_dataset_4 = test_parts\n",
    "\n",
    "# Print the sizes of the subsets\n",
    "print(f\"Train dataset parts sizes: {[get_dataset_size(part) for part in train_parts]}\")\n",
    "print(f\"Validation dataset parts sizes: {[get_dataset_size(part) for part in validation_parts]}\")\n",
    "print(f\"Test dataset parts sizes: {[get_dataset_size(part) for part in test_parts]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ssl\n",
    "#import requests\n",
    "\n",
    "#requests.packages.urllib3.disable_warnings()\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "#response = requests.get('https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "\n",
    "conv_base = VGG19(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset): \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = keras.applications.vgg19.preprocess_input(images) \n",
    "        features = conv_base.predict(preprocessed_images) \n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 179s 179s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features/train_features_1.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Save train features and labels\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures/train_features_1.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_features_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures/train_labels_1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, train_labels_1)\n\u001b[1;32m     27\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures/val_features_1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, val_features_1)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'features/train_features_1.npy'"
     ]
    }
   ],
   "source": [
    "#Dividimos o dataset em quatro partes\n",
    "#1/4\n",
    "#train_features_1, train_labels_1 = get_features_and_labels(train_dataset_1)\n",
    "#val_features_1, val_labels_1 = get_features_and_labels(validation_dataset_1)\n",
    "#test_features_1, test_labels_1 = get_features_and_labels(test_dataset_1)\n",
    "\n",
    "#2/4\n",
    "#train_features_2, train_labels_2 = get_features_and_labels(train_dataset_2)\n",
    "#val_features_2, val_labels_2 = get_features_and_labels(validation_dataset_2)\n",
    "#test_features_2, test_labels_2 = get_features_and_labels(test_dataset_2)\n",
    "\n",
    "#3/4\n",
    "#train_features_3, train_labels_3 = get_features_and_labels(train_dataset_3)\n",
    "#val_features_3, val_labels_3 = get_features_and_labels(validation_dataset_3)\n",
    "#test_features_3, test_labels_3 = get_features_and_labels(test_dataset_3)\n",
    "\n",
    "#4/4\n",
    "#train_features_4, train_labels_4 = get_features_and_labels(train_dataset_4)\n",
    "#val_features_4, val_labels_4 = get_features_and_labels(validation_dataset_4)\n",
    "#test_features_4, test_labels_4 = get_features_and_labels(test_dataset_4)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Save train features and labels\n",
    "#np.save('features/train_features_1.npy', train_features_1)\n",
    "#np.save('features/train_labels_1.npy', train_labels_1)\n",
    "#np.save('features/val_features_1.npy', val_features_1)\n",
    "#np.save('features/val_labels_1.npy', val_labels_1)\n",
    "\n",
    "#np.save('features/train_features_2.npy', train_features_2)\n",
    "#np.save('features/train_labels_2.npy', train_labels_2)\n",
    "#np.save('features/val_features_2.npy', val_features_2)\n",
    "#np.save('features/val_labels_2.npy', val_labels_2)\n",
    "\n",
    "#np.save('features/train_features_3.npy', train_features_3)\n",
    "#np.save('features/train_labels_3.npy', train_labels_3)\n",
    "#np.save('features/val_features_3.npy', val_features_3)\n",
    "#np.save('features/val_labels_3.npy', val_labels_3)\n",
    "\n",
    "#np.save('features/train_features_4.npy', train_features_4)\n",
    "#np.save('features/train_labels_4.npy', train_labels_4)\n",
    "#np.save('features/val_features_4.npy', val_features_4)\n",
    "#np.save('features/val_labels_4.npy', val_labels_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load train features and labels\n",
    "train_features_1 = np.load('features/train_features_1.npy')\n",
    "train_labels_1 = np.load('features/train_labels_1.npy')\n",
    "val_features_1 = np.load('features/val_features_1.npy')\n",
    "val_labels_1 = np.load('features/val_labels_1.npy')\n",
    "\n",
    "#train_features_2 = np.load('train_features_2.npy')\n",
    "#train_labels_2 = np.load('train_labels_2.npy')\n",
    "#val_features_2 = np.load('val_features_2.npy')\n",
    "#val_labels_2 = np.load('val_labels_2.npy')\n",
    "\n",
    "#train_features_3 = np.load('train_features_3.npy')\n",
    "#train_labels_3 = np.load('train_labels_3.npy')\n",
    "#val_features_3 = np.load('val_features_3.npy')\n",
    "#val_labels_3 = np.load('val_labels_3.npy')\n",
    "\n",
    "#train_features_4 = np.load('train_features_4.npy')\n",
    "#train_labels_4 = np.load('train_labels_4.npy')\n",
    "#val_features_4 = np.load('val_features_4.npy')\n",
    "#val_labels_4 = np.load('val_labels_4.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20024384 (76.39 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 20024384 (76.39 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "inputs = keras.Input(shape=(4, 4, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.6)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A partir deste bloco iremos treinar o modelo para os sub datasets\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-5, weight_decay=1e-2),metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=80, restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "312/312 [==============================] - 12s 35ms/step - loss: 2.6446 - accuracy: 0.2833 - val_loss: 1.1430 - val_accuracy: 0.6206\n",
      "Epoch 2/120\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 1.4778 - accuracy: 0.5439 - val_loss: 0.8171 - val_accuracy: 0.7312\n",
      "Epoch 3/120\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 1.0896 - accuracy: 0.6534 - val_loss: 0.6926 - val_accuracy: 0.7728\n",
      "Epoch 4/120\n",
      "312/312 [==============================] - 10s 34ms/step - loss: 0.8982 - accuracy: 0.7091 - val_loss: 0.6268 - val_accuracy: 0.7989\n",
      "Epoch 5/120\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 0.7803 - accuracy: 0.7489 - val_loss: 0.5835 - val_accuracy: 0.8113\n",
      "Epoch 6/120\n",
      "312/312 [==============================] - 10s 34ms/step - loss: 0.6787 - accuracy: 0.7774 - val_loss: 0.5552 - val_accuracy: 0.8217\n",
      "Epoch 7/120\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 0.6096 - accuracy: 0.8034 - val_loss: 0.5318 - val_accuracy: 0.8293\n",
      "Epoch 8/120\n",
      "312/312 [==============================] - 10s 34ms/step - loss: 0.5388 - accuracy: 0.8242 - val_loss: 0.5160 - val_accuracy: 0.8357\n",
      "Epoch 9/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.4902 - accuracy: 0.8342 - val_loss: 0.5010 - val_accuracy: 0.8385\n",
      "Epoch 10/120\n",
      "312/312 [==============================] - 10s 34ms/step - loss: 0.4556 - accuracy: 0.8470 - val_loss: 0.4924 - val_accuracy: 0.8405\n",
      "Epoch 11/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.4103 - accuracy: 0.8627 - val_loss: 0.4810 - val_accuracy: 0.8429\n",
      "Epoch 12/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.3856 - accuracy: 0.8669 - val_loss: 0.4750 - val_accuracy: 0.8450\n",
      "Epoch 13/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.3387 - accuracy: 0.8840 - val_loss: 0.4692 - val_accuracy: 0.8490\n",
      "Epoch 14/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.3238 - accuracy: 0.8883 - val_loss: 0.4637 - val_accuracy: 0.8502\n",
      "Epoch 15/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.2883 - accuracy: 0.9001 - val_loss: 0.4571 - val_accuracy: 0.8518\n",
      "Epoch 16/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.2737 - accuracy: 0.9099 - val_loss: 0.4556 - val_accuracy: 0.8514\n",
      "Epoch 17/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.2576 - accuracy: 0.9144 - val_loss: 0.4488 - val_accuracy: 0.8526\n",
      "Epoch 18/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.2253 - accuracy: 0.9245 - val_loss: 0.4479 - val_accuracy: 0.8570\n",
      "Epoch 19/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.2101 - accuracy: 0.9272 - val_loss: 0.4425 - val_accuracy: 0.8558\n",
      "Epoch 20/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1871 - accuracy: 0.9392 - val_loss: 0.4395 - val_accuracy: 0.8558\n",
      "Epoch 21/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1885 - accuracy: 0.9350 - val_loss: 0.4372 - val_accuracy: 0.8594\n",
      "Epoch 22/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1718 - accuracy: 0.9437 - val_loss: 0.4340 - val_accuracy: 0.8602\n",
      "Epoch 23/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1545 - accuracy: 0.9491 - val_loss: 0.4346 - val_accuracy: 0.8618\n",
      "Epoch 24/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1510 - accuracy: 0.9507 - val_loss: 0.4332 - val_accuracy: 0.8618\n",
      "Epoch 25/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.1376 - accuracy: 0.9573 - val_loss: 0.4319 - val_accuracy: 0.8630\n",
      "Epoch 26/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.1265 - accuracy: 0.9591 - val_loss: 0.4302 - val_accuracy: 0.8642\n",
      "Epoch 27/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.1102 - accuracy: 0.9645 - val_loss: 0.4298 - val_accuracy: 0.8646\n",
      "Epoch 28/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.1109 - accuracy: 0.9664 - val_loss: 0.4271 - val_accuracy: 0.8638\n",
      "Epoch 29/120\n",
      "312/312 [==============================] - 12s 38ms/step - loss: 0.1010 - accuracy: 0.9712 - val_loss: 0.4258 - val_accuracy: 0.8658\n",
      "Epoch 30/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.1022 - accuracy: 0.9701 - val_loss: 0.4286 - val_accuracy: 0.8642\n",
      "Epoch 31/120\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.0867 - accuracy: 0.9761 - val_loss: 0.4278 - val_accuracy: 0.8626\n",
      "Epoch 32/120\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.0819 - accuracy: 0.9763 - val_loss: 0.4268 - val_accuracy: 0.8650\n",
      "Epoch 33/120\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.0778 - accuracy: 0.9781 - val_loss: 0.4303 - val_accuracy: 0.8654\n",
      "Epoch 34/120\n",
      "312/312 [==============================] - 11s 37ms/step - loss: 0.0758 - accuracy: 0.9794 - val_loss: 0.4286 - val_accuracy: 0.8650\n",
      "Epoch 35/120\n",
      "312/312 [==============================] - 11s 37ms/step - loss: 0.0726 - accuracy: 0.9801 - val_loss: 0.4276 - val_accuracy: 0.8666\n",
      "Epoch 36/120\n",
      "312/312 [==============================] - 12s 37ms/step - loss: 0.0667 - accuracy: 0.9824 - val_loss: 0.4284 - val_accuracy: 0.8654\n",
      "Epoch 37/120\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.0620 - accuracy: 0.9841 - val_loss: 0.4302 - val_accuracy: 0.8682\n",
      "Epoch 38/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.4298 - val_accuracy: 0.8650\n",
      "Epoch 39/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.0571 - accuracy: 0.9856 - val_loss: 0.4293 - val_accuracy: 0.8650\n",
      "Epoch 40/120\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.0581 - accuracy: 0.9863 - val_loss: 0.4299 - val_accuracy: 0.8658\n",
      "Epoch 41/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.0529 - accuracy: 0.9866 - val_loss: 0.4312 - val_accuracy: 0.8674\n",
      "Epoch 42/120\n",
      "312/312 [==============================] - 11s 35ms/step - loss: 0.0475 - accuracy: 0.9897 - val_loss: 0.4313 - val_accuracy: 0.8702\n",
      "Epoch 43/120\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.0432 - accuracy: 0.9904 - val_loss: 0.4322 - val_accuracy: 0.8682\n",
      "Epoch 44/120\n",
      "183/312 [================>.............] - ETA: 4s - loss: 0.0417 - accuracy: 0.9918"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[185], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_features_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features_1, train_labels_1,epochs=120, batch_size=32, validation_data=(val_features_1, val_labels_1),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc,'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss,'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 35s 35s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 231s 231s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 260s 260s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 9s 9s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 104s 104s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 29s 29s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 203s 203s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "#Get features dataset 2/4\n",
    "train_features_2, train_labels_2 = get_features_and_labels(train_dataset_2)\n",
    "val_features_2, val_labels_2 = get_features_and_labels(validation_dataset_2)\n",
    "#test_features_2, test_labels_2 = get_features_and_labels(test_dataset_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "312/312 [==============================] - 8s 18ms/step - loss: 3.3778 - accuracy: 0.1122 - val_loss: 2.5288 - val_accuracy: 0.1426 - lr: 1.0000e-06\n",
      "Epoch 2/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 3.3426 - accuracy: 0.1118 - val_loss: 2.5125 - val_accuracy: 0.1422 - lr: 1.0000e-06\n",
      "Epoch 3/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.3657 - accuracy: 0.1096 - val_loss: 2.5112 - val_accuracy: 0.1454 - lr: 1.0000e-06\n",
      "Epoch 4/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.3219 - accuracy: 0.1142 - val_loss: 2.4973 - val_accuracy: 0.1474 - lr: 1.0000e-06\n",
      "Epoch 5/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 3.3315 - accuracy: 0.1196 - val_loss: 2.4852 - val_accuracy: 0.1518 - lr: 1.0000e-06\n",
      "Epoch 6/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.3208 - accuracy: 0.1157 - val_loss: 2.4702 - val_accuracy: 0.1583 - lr: 1.0000e-06\n",
      "Epoch 7/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.3132 - accuracy: 0.1153 - val_loss: 2.4676 - val_accuracy: 0.1538 - lr: 1.0000e-06\n",
      "Epoch 8/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.3083 - accuracy: 0.1162 - val_loss: 2.4614 - val_accuracy: 0.1554 - lr: 1.0000e-06\n",
      "Epoch 9/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.2776 - accuracy: 0.1193 - val_loss: 2.4496 - val_accuracy: 0.1607 - lr: 1.0000e-06\n",
      "Epoch 10/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 3.2766 - accuracy: 0.1210 - val_loss: 2.4333 - val_accuracy: 0.1639 - lr: 1.0000e-06\n",
      "Epoch 11/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.2588 - accuracy: 0.1199 - val_loss: 2.4225 - val_accuracy: 0.1651 - lr: 1.0000e-06\n",
      "Epoch 12/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.2731 - accuracy: 0.1161 - val_loss: 2.4255 - val_accuracy: 0.1691 - lr: 1.0000e-06\n",
      "Epoch 13/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 3.2480 - accuracy: 0.1170 - val_loss: 2.4128 - val_accuracy: 0.1715 - lr: 1.0000e-06\n",
      "Epoch 14/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.2310 - accuracy: 0.1259 - val_loss: 2.4070 - val_accuracy: 0.1715 - lr: 1.0000e-06\n",
      "Epoch 15/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 3.2053 - accuracy: 0.1245 - val_loss: 2.3925 - val_accuracy: 0.1735 - lr: 1.0000e-06\n",
      "Epoch 16/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.2257 - accuracy: 0.1202 - val_loss: 2.3813 - val_accuracy: 0.1747 - lr: 1.0000e-06\n",
      "Epoch 17/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.1817 - accuracy: 0.1208 - val_loss: 2.3746 - val_accuracy: 0.1779 - lr: 1.0000e-06\n",
      "Epoch 18/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.1869 - accuracy: 0.1281 - val_loss: 2.3636 - val_accuracy: 0.1843 - lr: 1.0000e-06\n",
      "Epoch 19/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.1692 - accuracy: 0.1306 - val_loss: 2.3527 - val_accuracy: 0.1835 - lr: 1.0000e-06\n",
      "Epoch 20/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1689 - accuracy: 0.1267 - val_loss: 2.3454 - val_accuracy: 0.1823 - lr: 1.0000e-06\n",
      "Epoch 21/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1826 - accuracy: 0.1267 - val_loss: 2.3400 - val_accuracy: 0.1851 - lr: 1.0000e-06\n",
      "Epoch 22/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1442 - accuracy: 0.1293 - val_loss: 2.3298 - val_accuracy: 0.1871 - lr: 1.0000e-06\n",
      "Epoch 23/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 3.1266 - accuracy: 0.1302 - val_loss: 2.3210 - val_accuracy: 0.1871 - lr: 1.0000e-06\n",
      "Epoch 24/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1571 - accuracy: 0.1300 - val_loss: 2.3087 - val_accuracy: 0.1931 - lr: 1.0000e-06\n",
      "Epoch 25/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1505 - accuracy: 0.1260 - val_loss: 2.2982 - val_accuracy: 0.1963 - lr: 1.0000e-06\n",
      "Epoch 26/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1313 - accuracy: 0.1341 - val_loss: 2.2931 - val_accuracy: 0.1983 - lr: 1.0000e-06\n",
      "Epoch 27/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0856 - accuracy: 0.1309 - val_loss: 2.2782 - val_accuracy: 0.1975 - lr: 1.0000e-06\n",
      "Epoch 28/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.1034 - accuracy: 0.1299 - val_loss: 2.2717 - val_accuracy: 0.2015 - lr: 1.0000e-06\n",
      "Epoch 29/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0833 - accuracy: 0.1337 - val_loss: 2.2690 - val_accuracy: 0.2031 - lr: 1.0000e-06\n",
      "Epoch 30/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.0791 - accuracy: 0.1379 - val_loss: 2.2565 - val_accuracy: 0.2039 - lr: 1.0000e-06\n",
      "Epoch 31/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0798 - accuracy: 0.1393 - val_loss: 2.2420 - val_accuracy: 0.2083 - lr: 1.0000e-06\n",
      "Epoch 32/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0758 - accuracy: 0.1416 - val_loss: 2.2392 - val_accuracy: 0.2043 - lr: 1.0000e-06\n",
      "Epoch 33/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0654 - accuracy: 0.1398 - val_loss: 2.2275 - val_accuracy: 0.2091 - lr: 1.0000e-06\n",
      "Epoch 34/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0446 - accuracy: 0.1377 - val_loss: 2.2205 - val_accuracy: 0.2135 - lr: 1.0000e-06\n",
      "Epoch 35/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0656 - accuracy: 0.1395 - val_loss: 2.2049 - val_accuracy: 0.2163 - lr: 1.0000e-06\n",
      "Epoch 36/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0500 - accuracy: 0.1394 - val_loss: 2.2012 - val_accuracy: 0.2204 - lr: 1.0000e-06\n",
      "Epoch 37/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 3.0028 - accuracy: 0.1409 - val_loss: 2.1925 - val_accuracy: 0.2244 - lr: 1.0000e-06\n",
      "Epoch 38/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0362 - accuracy: 0.1463 - val_loss: 2.1835 - val_accuracy: 0.2284 - lr: 1.0000e-06\n",
      "Epoch 39/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0011 - accuracy: 0.1491 - val_loss: 2.1836 - val_accuracy: 0.2260 - lr: 1.0000e-06\n",
      "Epoch 40/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 3.0011 - accuracy: 0.1490 - val_loss: 2.1674 - val_accuracy: 0.2336 - lr: 1.0000e-06\n",
      "Epoch 41/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.9843 - accuracy: 0.1454 - val_loss: 2.1597 - val_accuracy: 0.2360 - lr: 1.0000e-06\n",
      "Epoch 42/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.9907 - accuracy: 0.1479 - val_loss: 2.1463 - val_accuracy: 0.2420 - lr: 1.0000e-06\n",
      "Epoch 43/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.9710 - accuracy: 0.1504 - val_loss: 2.1454 - val_accuracy: 0.2432 - lr: 1.0000e-06\n",
      "Epoch 44/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.9662 - accuracy: 0.1449 - val_loss: 2.1408 - val_accuracy: 0.2428 - lr: 1.0000e-06\n",
      "Epoch 45/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9377 - accuracy: 0.1506 - val_loss: 2.1209 - val_accuracy: 0.2548 - lr: 1.0000e-06\n",
      "Epoch 46/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9671 - accuracy: 0.1474 - val_loss: 2.1239 - val_accuracy: 0.2488 - lr: 1.0000e-06\n",
      "Epoch 47/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9664 - accuracy: 0.1505 - val_loss: 2.1091 - val_accuracy: 0.2560 - lr: 1.0000e-06\n",
      "Epoch 48/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9402 - accuracy: 0.1536 - val_loss: 2.0995 - val_accuracy: 0.2588 - lr: 1.0000e-06\n",
      "Epoch 49/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9337 - accuracy: 0.1522 - val_loss: 2.0938 - val_accuracy: 0.2628 - lr: 1.0000e-06\n",
      "Epoch 50/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9259 - accuracy: 0.1558 - val_loss: 2.0824 - val_accuracy: 0.2668 - lr: 1.0000e-06\n",
      "Epoch 51/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8985 - accuracy: 0.1570 - val_loss: 2.0791 - val_accuracy: 0.2648 - lr: 1.0000e-06\n",
      "Epoch 52/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8964 - accuracy: 0.1621 - val_loss: 2.0637 - val_accuracy: 0.2720 - lr: 1.0000e-06\n",
      "Epoch 53/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8918 - accuracy: 0.1617 - val_loss: 2.0611 - val_accuracy: 0.2764 - lr: 1.0000e-06\n",
      "Epoch 54/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.9119 - accuracy: 0.1575 - val_loss: 2.0552 - val_accuracy: 0.2732 - lr: 1.0000e-06\n",
      "Epoch 55/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8482 - accuracy: 0.1676 - val_loss: 2.0438 - val_accuracy: 0.2756 - lr: 1.0000e-06\n",
      "Epoch 56/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8594 - accuracy: 0.1603 - val_loss: 2.0451 - val_accuracy: 0.2780 - lr: 1.0000e-06\n",
      "Epoch 57/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8629 - accuracy: 0.1597 - val_loss: 2.0368 - val_accuracy: 0.2772 - lr: 1.0000e-06\n",
      "Epoch 58/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.8565 - accuracy: 0.1637 - val_loss: 2.0259 - val_accuracy: 0.2837 - lr: 1.0000e-06\n",
      "Epoch 59/400\n",
      "312/312 [==============================] - 7s 22ms/step - loss: 2.8572 - accuracy: 0.1621 - val_loss: 2.0146 - val_accuracy: 0.2821 - lr: 1.0000e-06\n",
      "Epoch 60/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8354 - accuracy: 0.1690 - val_loss: 2.0115 - val_accuracy: 0.2825 - lr: 1.0000e-06\n",
      "Epoch 61/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8384 - accuracy: 0.1627 - val_loss: 2.0075 - val_accuracy: 0.2857 - lr: 1.0000e-06\n",
      "Epoch 62/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8135 - accuracy: 0.1695 - val_loss: 1.9962 - val_accuracy: 0.2961 - lr: 1.0000e-06\n",
      "Epoch 63/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.8211 - accuracy: 0.1692 - val_loss: 1.9848 - val_accuracy: 0.2989 - lr: 1.0000e-06\n",
      "Epoch 64/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7908 - accuracy: 0.1714 - val_loss: 1.9831 - val_accuracy: 0.3009 - lr: 1.0000e-06\n",
      "Epoch 65/400\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 2.7994 - accuracy: 0.1728 - val_loss: 1.9711 - val_accuracy: 0.3053 - lr: 1.0000e-06\n",
      "Epoch 66/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7852 - accuracy: 0.1731 - val_loss: 1.9717 - val_accuracy: 0.3005 - lr: 1.0000e-06\n",
      "Epoch 67/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 2.7804 - accuracy: 0.1700 - val_loss: 1.9530 - val_accuracy: 0.3089 - lr: 1.0000e-06\n",
      "Epoch 68/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7846 - accuracy: 0.1709 - val_loss: 1.9554 - val_accuracy: 0.3109 - lr: 1.0000e-06\n",
      "Epoch 69/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7632 - accuracy: 0.1805 - val_loss: 1.9415 - val_accuracy: 0.3141 - lr: 1.0000e-06\n",
      "Epoch 70/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7320 - accuracy: 0.1749 - val_loss: 1.9407 - val_accuracy: 0.3149 - lr: 1.0000e-06\n",
      "Epoch 71/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7601 - accuracy: 0.1767 - val_loss: 1.9346 - val_accuracy: 0.3153 - lr: 1.0000e-06\n",
      "Epoch 72/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.7495 - accuracy: 0.1750 - val_loss: 1.9278 - val_accuracy: 0.3193 - lr: 1.0000e-06\n",
      "Epoch 73/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7379 - accuracy: 0.1854 - val_loss: 1.9184 - val_accuracy: 0.3213 - lr: 1.0000e-06\n",
      "Epoch 74/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7251 - accuracy: 0.1874 - val_loss: 1.9140 - val_accuracy: 0.3241 - lr: 1.0000e-06\n",
      "Epoch 75/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7201 - accuracy: 0.1771 - val_loss: 1.9096 - val_accuracy: 0.3261 - lr: 1.0000e-06\n",
      "Epoch 76/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7289 - accuracy: 0.1806 - val_loss: 1.8986 - val_accuracy: 0.3321 - lr: 1.0000e-06\n",
      "Epoch 77/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.7011 - accuracy: 0.1828 - val_loss: 1.8945 - val_accuracy: 0.3321 - lr: 1.0000e-06\n",
      "Epoch 78/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6872 - accuracy: 0.1864 - val_loss: 1.8935 - val_accuracy: 0.3353 - lr: 1.0000e-06\n",
      "Epoch 79/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6926 - accuracy: 0.1903 - val_loss: 1.8853 - val_accuracy: 0.3446 - lr: 1.0000e-06\n",
      "Epoch 80/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6832 - accuracy: 0.1876 - val_loss: 1.8800 - val_accuracy: 0.3361 - lr: 1.0000e-06\n",
      "Epoch 81/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6718 - accuracy: 0.1825 - val_loss: 1.8752 - val_accuracy: 0.3417 - lr: 1.0000e-06\n",
      "Epoch 82/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6952 - accuracy: 0.1891 - val_loss: 1.8667 - val_accuracy: 0.3470 - lr: 1.0000e-06\n",
      "Epoch 83/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6711 - accuracy: 0.1888 - val_loss: 1.8555 - val_accuracy: 0.3506 - lr: 1.0000e-06\n",
      "Epoch 84/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 2.6639 - accuracy: 0.1905 - val_loss: 1.8556 - val_accuracy: 0.3538 - lr: 1.0000e-06\n",
      "Epoch 85/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6523 - accuracy: 0.1958 - val_loss: 1.8504 - val_accuracy: 0.3534 - lr: 1.0000e-06\n",
      "Epoch 86/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6706 - accuracy: 0.1896 - val_loss: 1.8336 - val_accuracy: 0.3590 - lr: 1.0000e-06\n",
      "Epoch 87/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6422 - accuracy: 0.1925 - val_loss: 1.8379 - val_accuracy: 0.3594 - lr: 1.0000e-06\n",
      "Epoch 88/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6507 - accuracy: 0.1879 - val_loss: 1.8256 - val_accuracy: 0.3690 - lr: 1.0000e-06\n",
      "Epoch 89/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.6461 - accuracy: 0.1903 - val_loss: 1.8169 - val_accuracy: 0.3742 - lr: 1.0000e-06\n",
      "Epoch 90/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6283 - accuracy: 0.1960 - val_loss: 1.8124 - val_accuracy: 0.3766 - lr: 1.0000e-06\n",
      "Epoch 91/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6150 - accuracy: 0.1954 - val_loss: 1.8103 - val_accuracy: 0.3778 - lr: 1.0000e-06\n",
      "Epoch 92/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6130 - accuracy: 0.2001 - val_loss: 1.8058 - val_accuracy: 0.3758 - lr: 1.0000e-06\n",
      "Epoch 93/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6190 - accuracy: 0.1971 - val_loss: 1.8066 - val_accuracy: 0.3774 - lr: 1.0000e-06\n",
      "Epoch 94/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.5944 - accuracy: 0.2072 - val_loss: 1.7998 - val_accuracy: 0.3838 - lr: 1.0000e-06\n",
      "Epoch 95/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.6022 - accuracy: 0.2022 - val_loss: 1.7946 - val_accuracy: 0.3834 - lr: 1.0000e-06\n",
      "Epoch 96/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.5696 - accuracy: 0.2092 - val_loss: 1.7861 - val_accuracy: 0.3886 - lr: 1.0000e-06\n",
      "Epoch 97/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5619 - accuracy: 0.2061 - val_loss: 1.7735 - val_accuracy: 0.3934 - lr: 1.0000e-06\n",
      "Epoch 98/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5745 - accuracy: 0.2033 - val_loss: 1.7663 - val_accuracy: 0.3966 - lr: 1.0000e-06\n",
      "Epoch 99/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5697 - accuracy: 0.2024 - val_loss: 1.7724 - val_accuracy: 0.3858 - lr: 1.0000e-06\n",
      "Epoch 100/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5643 - accuracy: 0.2038 - val_loss: 1.7614 - val_accuracy: 0.3910 - lr: 1.0000e-06\n",
      "Epoch 101/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5705 - accuracy: 0.2021 - val_loss: 1.7554 - val_accuracy: 0.3990 - lr: 1.0000e-06\n",
      "Epoch 102/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5606 - accuracy: 0.2119 - val_loss: 1.7479 - val_accuracy: 0.4002 - lr: 1.0000e-06\n",
      "Epoch 103/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5332 - accuracy: 0.2147 - val_loss: 1.7480 - val_accuracy: 0.3990 - lr: 1.0000e-06\n",
      "Epoch 104/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.5348 - accuracy: 0.2097 - val_loss: 1.7411 - val_accuracy: 0.4034 - lr: 1.0000e-06\n",
      "Epoch 105/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5568 - accuracy: 0.2097 - val_loss: 1.7345 - val_accuracy: 0.4087 - lr: 1.0000e-06\n",
      "Epoch 106/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.5140 - accuracy: 0.2157 - val_loss: 1.7267 - val_accuracy: 0.4103 - lr: 1.0000e-06\n",
      "Epoch 107/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.5087 - accuracy: 0.2172 - val_loss: 1.7247 - val_accuracy: 0.4115 - lr: 1.0000e-06\n",
      "Epoch 108/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.5477 - accuracy: 0.2067 - val_loss: 1.7233 - val_accuracy: 0.4091 - lr: 1.0000e-06\n",
      "Epoch 109/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.4960 - accuracy: 0.2170 - val_loss: 1.7156 - val_accuracy: 0.4147 - lr: 1.0000e-06\n",
      "Epoch 110/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 2.5123 - accuracy: 0.2134 - val_loss: 1.7111 - val_accuracy: 0.4199 - lr: 1.0000e-06\n",
      "Epoch 111/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.4931 - accuracy: 0.2203 - val_loss: 1.7072 - val_accuracy: 0.4191 - lr: 1.0000e-06\n",
      "Epoch 112/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.4820 - accuracy: 0.2233 - val_loss: 1.7008 - val_accuracy: 0.4211 - lr: 1.0000e-06\n",
      "Epoch 113/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.4894 - accuracy: 0.2183 - val_loss: 1.6924 - val_accuracy: 0.4255 - lr: 1.0000e-06\n",
      "Epoch 114/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.4845 - accuracy: 0.2177 - val_loss: 1.6842 - val_accuracy: 0.4327 - lr: 1.0000e-06\n",
      "Epoch 115/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.4795 - accuracy: 0.2218 - val_loss: 1.6829 - val_accuracy: 0.4323 - lr: 1.0000e-06\n",
      "Epoch 116/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4511 - accuracy: 0.2295 - val_loss: 1.6825 - val_accuracy: 0.4307 - lr: 1.0000e-06\n",
      "Epoch 117/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 2.4688 - accuracy: 0.2266 - val_loss: 1.6877 - val_accuracy: 0.4299 - lr: 1.0000e-06\n",
      "Epoch 118/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4502 - accuracy: 0.2295 - val_loss: 1.6726 - val_accuracy: 0.4347 - lr: 1.0000e-06\n",
      "Epoch 119/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4558 - accuracy: 0.2246 - val_loss: 1.6656 - val_accuracy: 0.4407 - lr: 1.0000e-06\n",
      "Epoch 120/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4581 - accuracy: 0.2244 - val_loss: 1.6623 - val_accuracy: 0.4459 - lr: 1.0000e-06\n",
      "Epoch 121/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4529 - accuracy: 0.2223 - val_loss: 1.6507 - val_accuracy: 0.4495 - lr: 1.0000e-06\n",
      "Epoch 122/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4669 - accuracy: 0.2231 - val_loss: 1.6512 - val_accuracy: 0.4483 - lr: 1.0000e-06\n",
      "Epoch 123/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4471 - accuracy: 0.2227 - val_loss: 1.6465 - val_accuracy: 0.4523 - lr: 1.0000e-06\n",
      "Epoch 124/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4083 - accuracy: 0.2345 - val_loss: 1.6448 - val_accuracy: 0.4507 - lr: 1.0000e-06\n",
      "Epoch 125/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4175 - accuracy: 0.2360 - val_loss: 1.6435 - val_accuracy: 0.4519 - lr: 1.0000e-06\n",
      "Epoch 126/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4210 - accuracy: 0.2358 - val_loss: 1.6403 - val_accuracy: 0.4535 - lr: 1.0000e-06\n",
      "Epoch 127/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4244 - accuracy: 0.2344 - val_loss: 1.6378 - val_accuracy: 0.4527 - lr: 1.0000e-06\n",
      "Epoch 128/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3763 - accuracy: 0.2421 - val_loss: 1.6265 - val_accuracy: 0.4591 - lr: 1.0000e-06\n",
      "Epoch 129/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4054 - accuracy: 0.2327 - val_loss: 1.6212 - val_accuracy: 0.4623 - lr: 1.0000e-06\n",
      "Epoch 130/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.4146 - accuracy: 0.2383 - val_loss: 1.6222 - val_accuracy: 0.4607 - lr: 1.0000e-06\n",
      "Epoch 131/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3896 - accuracy: 0.2375 - val_loss: 1.6145 - val_accuracy: 0.4647 - lr: 1.0000e-06\n",
      "Epoch 132/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3735 - accuracy: 0.2369 - val_loss: 1.6106 - val_accuracy: 0.4688 - lr: 1.0000e-06\n",
      "Epoch 133/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3666 - accuracy: 0.2415 - val_loss: 1.6053 - val_accuracy: 0.4740 - lr: 1.0000e-06\n",
      "Epoch 134/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3912 - accuracy: 0.2391 - val_loss: 1.6045 - val_accuracy: 0.4675 - lr: 1.0000e-06\n",
      "Epoch 135/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 2.3695 - accuracy: 0.2432 - val_loss: 1.5998 - val_accuracy: 0.4752 - lr: 1.0000e-06\n",
      "Epoch 136/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3720 - accuracy: 0.2400 - val_loss: 1.5985 - val_accuracy: 0.4772 - lr: 1.0000e-06\n",
      "Epoch 137/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3484 - accuracy: 0.2380 - val_loss: 1.5943 - val_accuracy: 0.4784 - lr: 1.0000e-06\n",
      "Epoch 138/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3602 - accuracy: 0.2445 - val_loss: 1.5828 - val_accuracy: 0.4800 - lr: 1.0000e-06\n",
      "Epoch 139/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3596 - accuracy: 0.2435 - val_loss: 1.5831 - val_accuracy: 0.4800 - lr: 1.0000e-06\n",
      "Epoch 140/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3529 - accuracy: 0.2466 - val_loss: 1.5779 - val_accuracy: 0.4796 - lr: 1.0000e-06\n",
      "Epoch 141/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3590 - accuracy: 0.2459 - val_loss: 1.5773 - val_accuracy: 0.4808 - lr: 1.0000e-06\n",
      "Epoch 142/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3848 - accuracy: 0.2359 - val_loss: 1.5741 - val_accuracy: 0.4812 - lr: 1.0000e-06\n",
      "Epoch 143/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3484 - accuracy: 0.2452 - val_loss: 1.5677 - val_accuracy: 0.4852 - lr: 1.0000e-06\n",
      "Epoch 144/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3284 - accuracy: 0.2484 - val_loss: 1.5665 - val_accuracy: 0.4876 - lr: 1.0000e-06\n",
      "Epoch 145/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3158 - accuracy: 0.2512 - val_loss: 1.5642 - val_accuracy: 0.4864 - lr: 1.0000e-06\n",
      "Epoch 146/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3285 - accuracy: 0.2492 - val_loss: 1.5585 - val_accuracy: 0.4892 - lr: 1.0000e-06\n",
      "Epoch 147/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3052 - accuracy: 0.2490 - val_loss: 1.5526 - val_accuracy: 0.4932 - lr: 1.0000e-06\n",
      "Epoch 148/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3148 - accuracy: 0.2508 - val_loss: 1.5487 - val_accuracy: 0.4932 - lr: 1.0000e-06\n",
      "Epoch 149/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3182 - accuracy: 0.2558 - val_loss: 1.5337 - val_accuracy: 0.4984 - lr: 1.0000e-06\n",
      "Epoch 150/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3143 - accuracy: 0.2518 - val_loss: 1.5408 - val_accuracy: 0.4964 - lr: 1.0000e-06\n",
      "Epoch 151/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.3143 - accuracy: 0.2452 - val_loss: 1.5362 - val_accuracy: 0.4952 - lr: 1.0000e-06\n",
      "Epoch 152/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2719 - accuracy: 0.2638 - val_loss: 1.5393 - val_accuracy: 0.4972 - lr: 1.0000e-06\n",
      "Epoch 153/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.2807 - accuracy: 0.2594 - val_loss: 1.5286 - val_accuracy: 0.5024 - lr: 1.0000e-06\n",
      "Epoch 154/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2645 - accuracy: 0.2613 - val_loss: 1.5263 - val_accuracy: 0.5016 - lr: 1.0000e-06\n",
      "Epoch 155/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2710 - accuracy: 0.2626 - val_loss: 1.5209 - val_accuracy: 0.5060 - lr: 1.0000e-06\n",
      "Epoch 156/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2912 - accuracy: 0.2596 - val_loss: 1.5231 - val_accuracy: 0.5072 - lr: 1.0000e-06\n",
      "Epoch 157/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2822 - accuracy: 0.2563 - val_loss: 1.5152 - val_accuracy: 0.5108 - lr: 1.0000e-06\n",
      "Epoch 158/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2665 - accuracy: 0.2640 - val_loss: 1.5121 - val_accuracy: 0.5144 - lr: 1.0000e-06\n",
      "Epoch 159/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2427 - accuracy: 0.2706 - val_loss: 1.5109 - val_accuracy: 0.5156 - lr: 1.0000e-06\n",
      "Epoch 160/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.2528 - accuracy: 0.2629 - val_loss: 1.5098 - val_accuracy: 0.5176 - lr: 1.0000e-06\n",
      "Epoch 161/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.2327 - accuracy: 0.2712 - val_loss: 1.5004 - val_accuracy: 0.5200 - lr: 1.0000e-06\n",
      "Epoch 162/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.2229 - accuracy: 0.2671 - val_loss: 1.5002 - val_accuracy: 0.5228 - lr: 1.0000e-06\n",
      "Epoch 163/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.2581 - accuracy: 0.2655 - val_loss: 1.4925 - val_accuracy: 0.5248 - lr: 1.0000e-06\n",
      "Epoch 164/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2271 - accuracy: 0.2655 - val_loss: 1.4969 - val_accuracy: 0.5224 - lr: 1.0000e-06\n",
      "Epoch 165/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2461 - accuracy: 0.2651 - val_loss: 1.4874 - val_accuracy: 0.5272 - lr: 1.0000e-06\n",
      "Epoch 166/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2517 - accuracy: 0.2666 - val_loss: 1.4907 - val_accuracy: 0.5256 - lr: 1.0000e-06\n",
      "Epoch 167/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2247 - accuracy: 0.2756 - val_loss: 1.4820 - val_accuracy: 0.5296 - lr: 1.0000e-06\n",
      "Epoch 168/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2299 - accuracy: 0.2688 - val_loss: 1.4761 - val_accuracy: 0.5296 - lr: 1.0000e-06\n",
      "Epoch 169/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2159 - accuracy: 0.2703 - val_loss: 1.4752 - val_accuracy: 0.5365 - lr: 1.0000e-06\n",
      "Epoch 170/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2117 - accuracy: 0.2780 - val_loss: 1.4760 - val_accuracy: 0.5381 - lr: 1.0000e-06\n",
      "Epoch 171/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.2200 - accuracy: 0.2727 - val_loss: 1.4653 - val_accuracy: 0.5413 - lr: 1.0000e-06\n",
      "Epoch 172/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.1823 - accuracy: 0.2799 - val_loss: 1.4638 - val_accuracy: 0.5421 - lr: 1.0000e-06\n",
      "Epoch 173/400\n",
      "312/312 [==============================] - 67s 217ms/step - loss: 2.1940 - accuracy: 0.2757 - val_loss: 1.4623 - val_accuracy: 0.5401 - lr: 1.0000e-06\n",
      "Epoch 174/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 2.1977 - accuracy: 0.2732 - val_loss: 1.4590 - val_accuracy: 0.5433 - lr: 1.0000e-06\n",
      "Epoch 175/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 2.1895 - accuracy: 0.2806 - val_loss: 1.4563 - val_accuracy: 0.5449 - lr: 1.0000e-06\n",
      "Epoch 176/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1873 - accuracy: 0.2836 - val_loss: 1.4541 - val_accuracy: 0.5473 - lr: 1.0000e-06\n",
      "Epoch 177/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1721 - accuracy: 0.2758 - val_loss: 1.4491 - val_accuracy: 0.5461 - lr: 1.0000e-06\n",
      "Epoch 178/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.1791 - accuracy: 0.2779 - val_loss: 1.4569 - val_accuracy: 0.5437 - lr: 1.0000e-06\n",
      "Epoch 179/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1723 - accuracy: 0.2780 - val_loss: 1.4505 - val_accuracy: 0.5481 - lr: 1.0000e-06\n",
      "Epoch 180/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.1740 - accuracy: 0.2820 - val_loss: 1.4435 - val_accuracy: 0.5505 - lr: 1.0000e-06\n",
      "Epoch 181/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.1562 - accuracy: 0.2870 - val_loss: 1.4418 - val_accuracy: 0.5505 - lr: 1.0000e-06\n",
      "Epoch 182/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.1748 - accuracy: 0.2793 - val_loss: 1.4356 - val_accuracy: 0.5537 - lr: 1.0000e-06\n",
      "Epoch 183/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1628 - accuracy: 0.2868 - val_loss: 1.4363 - val_accuracy: 0.5553 - lr: 1.0000e-06\n",
      "Epoch 184/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.1557 - accuracy: 0.2847 - val_loss: 1.4353 - val_accuracy: 0.5585 - lr: 1.0000e-06\n",
      "Epoch 185/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1335 - accuracy: 0.2847 - val_loss: 1.4296 - val_accuracy: 0.5589 - lr: 1.0000e-06\n",
      "Epoch 186/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1356 - accuracy: 0.2914 - val_loss: 1.4262 - val_accuracy: 0.5597 - lr: 1.0000e-06\n",
      "Epoch 187/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1434 - accuracy: 0.2894 - val_loss: 1.4249 - val_accuracy: 0.5593 - lr: 1.0000e-06\n",
      "Epoch 188/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1507 - accuracy: 0.2932 - val_loss: 1.4224 - val_accuracy: 0.5617 - lr: 1.0000e-06\n",
      "Epoch 189/400\n",
      "312/312 [==============================] - 5s 16ms/step - loss: 2.1454 - accuracy: 0.2916 - val_loss: 1.4253 - val_accuracy: 0.5589 - lr: 1.0000e-06\n",
      "Epoch 190/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1539 - accuracy: 0.2860 - val_loss: 1.4133 - val_accuracy: 0.5685 - lr: 1.0000e-06\n",
      "Epoch 191/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1197 - accuracy: 0.2881 - val_loss: 1.4142 - val_accuracy: 0.5737 - lr: 1.0000e-06\n",
      "Epoch 192/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.1184 - accuracy: 0.2966 - val_loss: 1.4092 - val_accuracy: 0.5721 - lr: 1.0000e-06\n",
      "Epoch 193/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1207 - accuracy: 0.2923 - val_loss: 1.4100 - val_accuracy: 0.5689 - lr: 1.0000e-06\n",
      "Epoch 194/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1368 - accuracy: 0.2930 - val_loss: 1.4057 - val_accuracy: 0.5765 - lr: 1.0000e-06\n",
      "Epoch 195/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1089 - accuracy: 0.2997 - val_loss: 1.4066 - val_accuracy: 0.5701 - lr: 1.0000e-06\n",
      "Epoch 196/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.0905 - accuracy: 0.2994 - val_loss: 1.3913 - val_accuracy: 0.5765 - lr: 1.0000e-06\n",
      "Epoch 197/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 2.1280 - accuracy: 0.2940 - val_loss: 1.3973 - val_accuracy: 0.5753 - lr: 1.0000e-06\n",
      "Epoch 198/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.1079 - accuracy: 0.2939 - val_loss: 1.3884 - val_accuracy: 0.5833 - lr: 1.0000e-06\n",
      "Epoch 199/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0949 - accuracy: 0.2932 - val_loss: 1.3892 - val_accuracy: 0.5825 - lr: 1.0000e-06\n",
      "Epoch 200/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 2.0732 - accuracy: 0.3050 - val_loss: 1.3871 - val_accuracy: 0.5825 - lr: 1.0000e-06\n",
      "Epoch 201/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.1010 - accuracy: 0.2944 - val_loss: 1.3827 - val_accuracy: 0.5853 - lr: 1.0000e-06\n",
      "Epoch 202/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 2.0802 - accuracy: 0.3010 - val_loss: 1.3866 - val_accuracy: 0.5817 - lr: 1.0000e-06\n",
      "Epoch 203/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0779 - accuracy: 0.3020 - val_loss: 1.3818 - val_accuracy: 0.5845 - lr: 1.0000e-06\n",
      "Epoch 204/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0882 - accuracy: 0.3100 - val_loss: 1.3766 - val_accuracy: 0.5897 - lr: 1.0000e-06\n",
      "Epoch 205/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0758 - accuracy: 0.3079 - val_loss: 1.3687 - val_accuracy: 0.5897 - lr: 1.0000e-06\n",
      "Epoch 206/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0653 - accuracy: 0.3041 - val_loss: 1.3759 - val_accuracy: 0.5885 - lr: 1.0000e-06\n",
      "Epoch 207/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0820 - accuracy: 0.3013 - val_loss: 1.3648 - val_accuracy: 0.5950 - lr: 1.0000e-06\n",
      "Epoch 208/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0912 - accuracy: 0.3073 - val_loss: 1.3693 - val_accuracy: 0.5933 - lr: 1.0000e-06\n",
      "Epoch 209/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0640 - accuracy: 0.3105 - val_loss: 1.3771 - val_accuracy: 0.5877 - lr: 1.0000e-06\n",
      "Epoch 210/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0733 - accuracy: 0.3043 - val_loss: 1.3678 - val_accuracy: 0.5942 - lr: 1.0000e-06\n",
      "Epoch 211/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0440 - accuracy: 0.3057 - val_loss: 1.3623 - val_accuracy: 0.5970 - lr: 1.0000e-06\n",
      "Epoch 212/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0187 - accuracy: 0.3164 - val_loss: 1.3550 - val_accuracy: 0.5970 - lr: 1.0000e-06\n",
      "Epoch 213/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0470 - accuracy: 0.3119 - val_loss: 1.3586 - val_accuracy: 0.5958 - lr: 1.0000e-06\n",
      "Epoch 214/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0661 - accuracy: 0.3045 - val_loss: 1.3537 - val_accuracy: 0.6002 - lr: 1.0000e-06\n",
      "Epoch 215/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0572 - accuracy: 0.3088 - val_loss: 1.3479 - val_accuracy: 0.6006 - lr: 1.0000e-06\n",
      "Epoch 216/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0301 - accuracy: 0.3160 - val_loss: 1.3536 - val_accuracy: 0.6002 - lr: 1.0000e-06\n",
      "Epoch 217/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0205 - accuracy: 0.3197 - val_loss: 1.3468 - val_accuracy: 0.6026 - lr: 1.0000e-06\n",
      "Epoch 218/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0247 - accuracy: 0.3116 - val_loss: 1.3419 - val_accuracy: 0.6030 - lr: 1.0000e-06\n",
      "Epoch 219/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0273 - accuracy: 0.3173 - val_loss: 1.3434 - val_accuracy: 0.6046 - lr: 1.0000e-06\n",
      "Epoch 220/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0303 - accuracy: 0.3150 - val_loss: 1.3399 - val_accuracy: 0.6006 - lr: 1.0000e-06\n",
      "Epoch 221/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0192 - accuracy: 0.3219 - val_loss: 1.3379 - val_accuracy: 0.6042 - lr: 1.0000e-06\n",
      "Epoch 222/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0059 - accuracy: 0.3282 - val_loss: 1.3449 - val_accuracy: 0.6030 - lr: 1.0000e-06\n",
      "Epoch 223/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0076 - accuracy: 0.3221 - val_loss: 1.3388 - val_accuracy: 0.6050 - lr: 1.0000e-06\n",
      "Epoch 224/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0109 - accuracy: 0.3186 - val_loss: 1.3300 - val_accuracy: 0.6074 - lr: 1.0000e-06\n",
      "Epoch 225/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0059 - accuracy: 0.3225 - val_loss: 1.3298 - val_accuracy: 0.6074 - lr: 1.0000e-06\n",
      "Epoch 226/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9869 - accuracy: 0.3202 - val_loss: 1.3212 - val_accuracy: 0.6098 - lr: 1.0000e-06\n",
      "Epoch 227/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 2.0052 - accuracy: 0.3221 - val_loss: 1.3246 - val_accuracy: 0.6102 - lr: 1.0000e-06\n",
      "Epoch 228/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9859 - accuracy: 0.3280 - val_loss: 1.3191 - val_accuracy: 0.6134 - lr: 1.0000e-06\n",
      "Epoch 229/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9938 - accuracy: 0.3234 - val_loss: 1.3092 - val_accuracy: 0.6122 - lr: 1.0000e-06\n",
      "Epoch 230/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9901 - accuracy: 0.3274 - val_loss: 1.3207 - val_accuracy: 0.6134 - lr: 1.0000e-06\n",
      "Epoch 231/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9939 - accuracy: 0.3277 - val_loss: 1.3110 - val_accuracy: 0.6146 - lr: 1.0000e-06\n",
      "Epoch 232/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9779 - accuracy: 0.3285 - val_loss: 1.3078 - val_accuracy: 0.6130 - lr: 1.0000e-06\n",
      "Epoch 233/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9731 - accuracy: 0.3363 - val_loss: 1.3079 - val_accuracy: 0.6174 - lr: 1.0000e-06\n",
      "Epoch 234/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9806 - accuracy: 0.3231 - val_loss: 1.3133 - val_accuracy: 0.6130 - lr: 1.0000e-06\n",
      "Epoch 235/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9848 - accuracy: 0.3266 - val_loss: 1.3075 - val_accuracy: 0.6162 - lr: 1.0000e-06\n",
      "Epoch 236/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9662 - accuracy: 0.3306 - val_loss: 1.3077 - val_accuracy: 0.6154 - lr: 1.0000e-06\n",
      "Epoch 237/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9726 - accuracy: 0.3317 - val_loss: 1.2978 - val_accuracy: 0.6218 - lr: 1.0000e-06\n",
      "Epoch 238/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9677 - accuracy: 0.3334 - val_loss: 1.2991 - val_accuracy: 0.6190 - lr: 1.0000e-06\n",
      "Epoch 239/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9638 - accuracy: 0.3377 - val_loss: 1.2971 - val_accuracy: 0.6234 - lr: 1.0000e-06\n",
      "Epoch 240/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9558 - accuracy: 0.3338 - val_loss: 1.2954 - val_accuracy: 0.6222 - lr: 1.0000e-06\n",
      "Epoch 241/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9500 - accuracy: 0.3412 - val_loss: 1.2914 - val_accuracy: 0.6234 - lr: 1.0000e-06\n",
      "Epoch 242/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9462 - accuracy: 0.3380 - val_loss: 1.2921 - val_accuracy: 0.6250 - lr: 1.0000e-06\n",
      "Epoch 243/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9521 - accuracy: 0.3386 - val_loss: 1.2847 - val_accuracy: 0.6242 - lr: 1.0000e-06\n",
      "Epoch 244/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9420 - accuracy: 0.3403 - val_loss: 1.2903 - val_accuracy: 0.6242 - lr: 1.0000e-06\n",
      "Epoch 245/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9415 - accuracy: 0.3383 - val_loss: 1.2899 - val_accuracy: 0.6242 - lr: 1.0000e-06\n",
      "Epoch 246/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9474 - accuracy: 0.3424 - val_loss: 1.2802 - val_accuracy: 0.6318 - lr: 1.0000e-06\n",
      "Epoch 247/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9456 - accuracy: 0.3419 - val_loss: 1.2783 - val_accuracy: 0.6318 - lr: 1.0000e-06\n",
      "Epoch 248/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9286 - accuracy: 0.3390 - val_loss: 1.2745 - val_accuracy: 0.6338 - lr: 1.0000e-06\n",
      "Epoch 249/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9260 - accuracy: 0.3472 - val_loss: 1.2763 - val_accuracy: 0.6330 - lr: 1.0000e-06\n",
      "Epoch 250/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9224 - accuracy: 0.3489 - val_loss: 1.2759 - val_accuracy: 0.6314 - lr: 1.0000e-06\n",
      "Epoch 251/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9122 - accuracy: 0.3468 - val_loss: 1.2757 - val_accuracy: 0.6338 - lr: 1.0000e-06\n",
      "Epoch 252/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9149 - accuracy: 0.3544 - val_loss: 1.2657 - val_accuracy: 0.6370 - lr: 1.0000e-06\n",
      "Epoch 253/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9393 - accuracy: 0.3428 - val_loss: 1.2677 - val_accuracy: 0.6366 - lr: 1.0000e-06\n",
      "Epoch 254/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9095 - accuracy: 0.3435 - val_loss: 1.2641 - val_accuracy: 0.6386 - lr: 1.0000e-06\n",
      "Epoch 255/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9022 - accuracy: 0.3503 - val_loss: 1.2604 - val_accuracy: 0.6386 - lr: 1.0000e-06\n",
      "Epoch 256/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8964 - accuracy: 0.3546 - val_loss: 1.2668 - val_accuracy: 0.6414 - lr: 1.0000e-06\n",
      "Epoch 257/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9184 - accuracy: 0.3395 - val_loss: 1.2705 - val_accuracy: 0.6378 - lr: 1.0000e-06\n",
      "Epoch 258/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9092 - accuracy: 0.3552 - val_loss: 1.2587 - val_accuracy: 0.6434 - lr: 1.0000e-06\n",
      "Epoch 259/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8752 - accuracy: 0.3521 - val_loss: 1.2620 - val_accuracy: 0.6410 - lr: 1.0000e-06\n",
      "Epoch 260/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9174 - accuracy: 0.3465 - val_loss: 1.2529 - val_accuracy: 0.6442 - lr: 1.0000e-06\n",
      "Epoch 261/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.9019 - accuracy: 0.3486 - val_loss: 1.2553 - val_accuracy: 0.6434 - lr: 1.0000e-06\n",
      "Epoch 262/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8795 - accuracy: 0.3608 - val_loss: 1.2485 - val_accuracy: 0.6454 - lr: 1.0000e-06\n",
      "Epoch 263/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8915 - accuracy: 0.3527 - val_loss: 1.2400 - val_accuracy: 0.6478 - lr: 1.0000e-06\n",
      "Epoch 264/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8785 - accuracy: 0.3541 - val_loss: 1.2398 - val_accuracy: 0.6522 - lr: 1.0000e-06\n",
      "Epoch 265/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8838 - accuracy: 0.3633 - val_loss: 1.2437 - val_accuracy: 0.6514 - lr: 1.0000e-06\n",
      "Epoch 266/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8787 - accuracy: 0.3515 - val_loss: 1.2330 - val_accuracy: 0.6558 - lr: 1.0000e-06\n",
      "Epoch 267/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8859 - accuracy: 0.3513 - val_loss: 1.2380 - val_accuracy: 0.6518 - lr: 1.0000e-06\n",
      "Epoch 268/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8678 - accuracy: 0.3621 - val_loss: 1.2357 - val_accuracy: 0.6506 - lr: 1.0000e-06\n",
      "Epoch 269/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8701 - accuracy: 0.3616 - val_loss: 1.2302 - val_accuracy: 0.6522 - lr: 1.0000e-06\n",
      "Epoch 270/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8810 - accuracy: 0.3585 - val_loss: 1.2304 - val_accuracy: 0.6575 - lr: 1.0000e-06\n",
      "Epoch 271/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8605 - accuracy: 0.3652 - val_loss: 1.2361 - val_accuracy: 0.6538 - lr: 1.0000e-06\n",
      "Epoch 272/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8595 - accuracy: 0.3574 - val_loss: 1.2232 - val_accuracy: 0.6567 - lr: 1.0000e-06\n",
      "Epoch 273/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8619 - accuracy: 0.3568 - val_loss: 1.2227 - val_accuracy: 0.6619 - lr: 1.0000e-06\n",
      "Epoch 274/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.8599 - accuracy: 0.3635 - val_loss: 1.2213 - val_accuracy: 0.6587 - lr: 1.0000e-06\n",
      "Epoch 275/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8758 - accuracy: 0.3555 - val_loss: 1.2249 - val_accuracy: 0.6615 - lr: 1.0000e-06\n",
      "Epoch 276/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8667 - accuracy: 0.3598 - val_loss: 1.2138 - val_accuracy: 0.6671 - lr: 1.0000e-06\n",
      "Epoch 277/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8516 - accuracy: 0.3618 - val_loss: 1.2200 - val_accuracy: 0.6631 - lr: 1.0000e-06\n",
      "Epoch 278/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8629 - accuracy: 0.3653 - val_loss: 1.2144 - val_accuracy: 0.6607 - lr: 1.0000e-06\n",
      "Epoch 279/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8545 - accuracy: 0.3647 - val_loss: 1.2118 - val_accuracy: 0.6663 - lr: 1.0000e-06\n",
      "Epoch 280/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8446 - accuracy: 0.3683 - val_loss: 1.2171 - val_accuracy: 0.6635 - lr: 1.0000e-06\n",
      "Epoch 281/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8438 - accuracy: 0.3670 - val_loss: 1.2159 - val_accuracy: 0.6663 - lr: 1.0000e-06\n",
      "Epoch 282/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8406 - accuracy: 0.3647 - val_loss: 1.2054 - val_accuracy: 0.6679 - lr: 1.0000e-06\n",
      "Epoch 283/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8431 - accuracy: 0.3630 - val_loss: 1.2029 - val_accuracy: 0.6691 - lr: 1.0000e-06\n",
      "Epoch 284/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8202 - accuracy: 0.3716 - val_loss: 1.2075 - val_accuracy: 0.6711 - lr: 1.0000e-06\n",
      "Epoch 285/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.8308 - accuracy: 0.3691 - val_loss: 1.2068 - val_accuracy: 0.6691 - lr: 1.0000e-06\n",
      "Epoch 286/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 1.8157 - accuracy: 0.3790 - val_loss: 1.1996 - val_accuracy: 0.6699 - lr: 1.0000e-06\n",
      "Epoch 287/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8123 - accuracy: 0.3750 - val_loss: 1.2001 - val_accuracy: 0.6699 - lr: 1.0000e-06\n",
      "Epoch 288/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8205 - accuracy: 0.3735 - val_loss: 1.1995 - val_accuracy: 0.6715 - lr: 1.0000e-06\n",
      "Epoch 289/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8208 - accuracy: 0.3728 - val_loss: 1.1973 - val_accuracy: 0.6703 - lr: 1.0000e-06\n",
      "Epoch 290/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8205 - accuracy: 0.3757 - val_loss: 1.1989 - val_accuracy: 0.6667 - lr: 1.0000e-06\n",
      "Epoch 291/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.8229 - accuracy: 0.3744 - val_loss: 1.1909 - val_accuracy: 0.6731 - lr: 1.0000e-06\n",
      "Epoch 292/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8121 - accuracy: 0.3769 - val_loss: 1.1928 - val_accuracy: 0.6715 - lr: 1.0000e-06\n",
      "Epoch 293/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8124 - accuracy: 0.3778 - val_loss: 1.1993 - val_accuracy: 0.6711 - lr: 1.0000e-06\n",
      "Epoch 294/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7992 - accuracy: 0.3834 - val_loss: 1.1994 - val_accuracy: 0.6727 - lr: 1.0000e-06\n",
      "Epoch 295/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8083 - accuracy: 0.3798 - val_loss: 1.1888 - val_accuracy: 0.6807 - lr: 1.0000e-06\n",
      "Epoch 296/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8089 - accuracy: 0.3808 - val_loss: 1.1867 - val_accuracy: 0.6755 - lr: 1.0000e-06\n",
      "Epoch 297/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7953 - accuracy: 0.3850 - val_loss: 1.1895 - val_accuracy: 0.6791 - lr: 1.0000e-06\n",
      "Epoch 298/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7966 - accuracy: 0.3809 - val_loss: 1.1820 - val_accuracy: 0.6759 - lr: 1.0000e-06\n",
      "Epoch 299/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7873 - accuracy: 0.3842 - val_loss: 1.1755 - val_accuracy: 0.6831 - lr: 1.0000e-06\n",
      "Epoch 300/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7979 - accuracy: 0.3802 - val_loss: 1.1824 - val_accuracy: 0.6751 - lr: 1.0000e-06\n",
      "Epoch 301/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7965 - accuracy: 0.3778 - val_loss: 1.1921 - val_accuracy: 0.6723 - lr: 1.0000e-06\n",
      "Epoch 302/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.8087 - accuracy: 0.3756 - val_loss: 1.1830 - val_accuracy: 0.6795 - lr: 1.0000e-06\n",
      "Epoch 303/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7796 - accuracy: 0.3974 - val_loss: 1.1864 - val_accuracy: 0.6739 - lr: 1.0000e-06\n",
      "Epoch 304/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7808 - accuracy: 0.3850 - val_loss: 1.1699 - val_accuracy: 0.6831 - lr: 1.0000e-06\n",
      "Epoch 305/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7864 - accuracy: 0.3889 - val_loss: 1.1682 - val_accuracy: 0.6843 - lr: 1.0000e-06\n",
      "Epoch 306/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7738 - accuracy: 0.3907 - val_loss: 1.1748 - val_accuracy: 0.6815 - lr: 1.0000e-06\n",
      "Epoch 307/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7786 - accuracy: 0.3878 - val_loss: 1.1656 - val_accuracy: 0.6855 - lr: 1.0000e-06\n",
      "Epoch 308/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7553 - accuracy: 0.3973 - val_loss: 1.1659 - val_accuracy: 0.6859 - lr: 1.0000e-06\n",
      "Epoch 309/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7767 - accuracy: 0.3893 - val_loss: 1.1621 - val_accuracy: 0.6875 - lr: 1.0000e-06\n",
      "Epoch 310/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7686 - accuracy: 0.3921 - val_loss: 1.1649 - val_accuracy: 0.6855 - lr: 1.0000e-06\n",
      "Epoch 311/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7587 - accuracy: 0.3907 - val_loss: 1.1601 - val_accuracy: 0.6871 - lr: 1.0000e-06\n",
      "Epoch 312/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7553 - accuracy: 0.3913 - val_loss: 1.1607 - val_accuracy: 0.6887 - lr: 1.0000e-06\n",
      "Epoch 313/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7587 - accuracy: 0.3950 - val_loss: 1.1593 - val_accuracy: 0.6895 - lr: 1.0000e-06\n",
      "Epoch 314/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7596 - accuracy: 0.3923 - val_loss: 1.1551 - val_accuracy: 0.6943 - lr: 1.0000e-06\n",
      "Epoch 315/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7476 - accuracy: 0.3940 - val_loss: 1.1478 - val_accuracy: 0.6939 - lr: 1.0000e-06\n",
      "Epoch 316/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7348 - accuracy: 0.4008 - val_loss: 1.1476 - val_accuracy: 0.6987 - lr: 1.0000e-06\n",
      "Epoch 317/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7571 - accuracy: 0.3952 - val_loss: 1.1494 - val_accuracy: 0.6915 - lr: 1.0000e-06\n",
      "Epoch 318/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7650 - accuracy: 0.3931 - val_loss: 1.1522 - val_accuracy: 0.6943 - lr: 1.0000e-06\n",
      "Epoch 319/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7490 - accuracy: 0.3915 - val_loss: 1.1521 - val_accuracy: 0.6963 - lr: 1.0000e-06\n",
      "Epoch 320/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7498 - accuracy: 0.3959 - val_loss: 1.1514 - val_accuracy: 0.6927 - lr: 1.0000e-06\n",
      "Epoch 321/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7361 - accuracy: 0.3990 - val_loss: 1.1473 - val_accuracy: 0.6935 - lr: 1.0000e-06\n",
      "Epoch 322/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7489 - accuracy: 0.3944 - val_loss: 1.1446 - val_accuracy: 0.6963 - lr: 1.0000e-06\n",
      "Epoch 323/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7236 - accuracy: 0.4094 - val_loss: 1.1476 - val_accuracy: 0.6971 - lr: 1.0000e-06\n",
      "Epoch 324/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7387 - accuracy: 0.3996 - val_loss: 1.1387 - val_accuracy: 0.7003 - lr: 1.0000e-06\n",
      "Epoch 325/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7177 - accuracy: 0.4020 - val_loss: 1.1375 - val_accuracy: 0.6987 - lr: 1.0000e-06\n",
      "Epoch 326/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7087 - accuracy: 0.4095 - val_loss: 1.1343 - val_accuracy: 0.7011 - lr: 1.0000e-06\n",
      "Epoch 327/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7091 - accuracy: 0.4084 - val_loss: 1.1376 - val_accuracy: 0.7043 - lr: 1.0000e-06\n",
      "Epoch 328/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7416 - accuracy: 0.4017 - val_loss: 1.1368 - val_accuracy: 0.7031 - lr: 1.0000e-06\n",
      "Epoch 329/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7227 - accuracy: 0.4044 - val_loss: 1.1355 - val_accuracy: 0.7023 - lr: 1.0000e-06\n",
      "Epoch 330/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7123 - accuracy: 0.4086 - val_loss: 1.1318 - val_accuracy: 0.7027 - lr: 1.0000e-06\n",
      "Epoch 331/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7007 - accuracy: 0.4132 - val_loss: 1.1265 - val_accuracy: 0.7071 - lr: 1.0000e-06\n",
      "Epoch 332/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7304 - accuracy: 0.3999 - val_loss: 1.1333 - val_accuracy: 0.7039 - lr: 1.0000e-06\n",
      "Epoch 333/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7076 - accuracy: 0.4088 - val_loss: 1.1279 - val_accuracy: 0.7035 - lr: 1.0000e-06\n",
      "Epoch 334/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7160 - accuracy: 0.4100 - val_loss: 1.1223 - val_accuracy: 0.7071 - lr: 1.0000e-06\n",
      "Epoch 335/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7201 - accuracy: 0.4094 - val_loss: 1.1244 - val_accuracy: 0.7103 - lr: 1.0000e-06\n",
      "Epoch 336/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6799 - accuracy: 0.4200 - val_loss: 1.1209 - val_accuracy: 0.7079 - lr: 1.0000e-06\n",
      "Epoch 337/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.7005 - accuracy: 0.4078 - val_loss: 1.1154 - val_accuracy: 0.7103 - lr: 1.0000e-06\n",
      "Epoch 338/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6968 - accuracy: 0.4160 - val_loss: 1.1206 - val_accuracy: 0.7071 - lr: 1.0000e-06\n",
      "Epoch 339/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6978 - accuracy: 0.4161 - val_loss: 1.1243 - val_accuracy: 0.7091 - lr: 1.0000e-06\n",
      "Epoch 340/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6886 - accuracy: 0.4209 - val_loss: 1.1179 - val_accuracy: 0.7099 - lr: 1.0000e-06\n",
      "Epoch 341/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6821 - accuracy: 0.4140 - val_loss: 1.1113 - val_accuracy: 0.7147 - lr: 1.0000e-06\n",
      "Epoch 342/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6886 - accuracy: 0.4195 - val_loss: 1.1160 - val_accuracy: 0.7135 - lr: 1.0000e-06\n",
      "Epoch 343/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6842 - accuracy: 0.4182 - val_loss: 1.1162 - val_accuracy: 0.7111 - lr: 1.0000e-06\n",
      "Epoch 344/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6759 - accuracy: 0.4194 - val_loss: 1.1103 - val_accuracy: 0.7179 - lr: 1.0000e-06\n",
      "Epoch 345/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6501 - accuracy: 0.4295 - val_loss: 1.1124 - val_accuracy: 0.7123 - lr: 1.0000e-06\n",
      "Epoch 346/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6879 - accuracy: 0.4171 - val_loss: 1.1082 - val_accuracy: 0.7131 - lr: 1.0000e-06\n",
      "Epoch 347/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6621 - accuracy: 0.4250 - val_loss: 1.1059 - val_accuracy: 0.7188 - lr: 1.0000e-06\n",
      "Epoch 348/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6688 - accuracy: 0.4244 - val_loss: 1.1018 - val_accuracy: 0.7192 - lr: 1.0000e-06\n",
      "Epoch 349/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6812 - accuracy: 0.4168 - val_loss: 1.1057 - val_accuracy: 0.7163 - lr: 1.0000e-06\n",
      "Epoch 350/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6726 - accuracy: 0.4284 - val_loss: 1.0983 - val_accuracy: 0.7183 - lr: 1.0000e-06\n",
      "Epoch 351/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6624 - accuracy: 0.4154 - val_loss: 1.0988 - val_accuracy: 0.7236 - lr: 1.0000e-06\n",
      "Epoch 352/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6672 - accuracy: 0.4217 - val_loss: 1.1029 - val_accuracy: 0.7212 - lr: 1.0000e-06\n",
      "Epoch 353/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6675 - accuracy: 0.4239 - val_loss: 1.0961 - val_accuracy: 0.7216 - lr: 1.0000e-06\n",
      "Epoch 354/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6515 - accuracy: 0.4259 - val_loss: 1.0966 - val_accuracy: 0.7232 - lr: 1.0000e-06\n",
      "Epoch 355/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6731 - accuracy: 0.4217 - val_loss: 1.0950 - val_accuracy: 0.7188 - lr: 1.0000e-06\n",
      "Epoch 356/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6571 - accuracy: 0.4273 - val_loss: 1.0965 - val_accuracy: 0.7192 - lr: 1.0000e-06\n",
      "Epoch 357/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6549 - accuracy: 0.4225 - val_loss: 1.0911 - val_accuracy: 0.7256 - lr: 1.0000e-06\n",
      "Epoch 358/400\n",
      "312/312 [==============================] - 201s 646ms/step - loss: 1.6484 - accuracy: 0.4266 - val_loss: 1.0904 - val_accuracy: 0.7248 - lr: 1.0000e-06\n",
      "Epoch 359/400\n",
      "312/312 [==============================] - 7s 23ms/step - loss: 1.6440 - accuracy: 0.4301 - val_loss: 1.0868 - val_accuracy: 0.7264 - lr: 1.0000e-06\n",
      "Epoch 360/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6487 - accuracy: 0.4234 - val_loss: 1.0842 - val_accuracy: 0.7252 - lr: 1.0000e-06\n",
      "Epoch 361/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 1.6405 - accuracy: 0.4251 - val_loss: 1.0900 - val_accuracy: 0.7244 - lr: 1.0000e-06\n",
      "Epoch 362/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6491 - accuracy: 0.4269 - val_loss: 1.0768 - val_accuracy: 0.7312 - lr: 1.0000e-06\n",
      "Epoch 363/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6511 - accuracy: 0.4293 - val_loss: 1.0806 - val_accuracy: 0.7260 - lr: 1.0000e-06\n",
      "Epoch 364/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6299 - accuracy: 0.4317 - val_loss: 1.0806 - val_accuracy: 0.7240 - lr: 1.0000e-06\n",
      "Epoch 365/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6449 - accuracy: 0.4343 - val_loss: 1.0817 - val_accuracy: 0.7260 - lr: 1.0000e-06\n",
      "Epoch 366/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6375 - accuracy: 0.4360 - val_loss: 1.0797 - val_accuracy: 0.7244 - lr: 1.0000e-06\n",
      "Epoch 367/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6654 - accuracy: 0.4227 - val_loss: 1.0788 - val_accuracy: 0.7268 - lr: 1.0000e-06\n",
      "Epoch 368/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6402 - accuracy: 0.4353 - val_loss: 1.0709 - val_accuracy: 0.7280 - lr: 1.0000e-06\n",
      "Epoch 369/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6368 - accuracy: 0.4350 - val_loss: 1.0764 - val_accuracy: 0.7224 - lr: 1.0000e-06\n",
      "Epoch 370/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6232 - accuracy: 0.4352 - val_loss: 1.0782 - val_accuracy: 0.7288 - lr: 1.0000e-06\n",
      "Epoch 371/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6181 - accuracy: 0.4412 - val_loss: 1.0692 - val_accuracy: 0.7308 - lr: 1.0000e-06\n",
      "Epoch 372/400\n",
      "312/312 [==============================] - 5s 18ms/step - loss: 1.6050 - accuracy: 0.4422 - val_loss: 1.0670 - val_accuracy: 0.7288 - lr: 1.0000e-06\n",
      "Epoch 373/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6155 - accuracy: 0.4433 - val_loss: 1.0766 - val_accuracy: 0.7304 - lr: 1.0000e-06\n",
      "Epoch 374/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 1.6337 - accuracy: 0.4400 - val_loss: 1.0686 - val_accuracy: 0.7344 - lr: 1.0000e-06\n",
      "Epoch 375/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6117 - accuracy: 0.4450 - val_loss: 1.0741 - val_accuracy: 0.7316 - lr: 1.0000e-06\n",
      "Epoch 376/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6141 - accuracy: 0.4392 - val_loss: 1.0625 - val_accuracy: 0.7332 - lr: 1.0000e-06\n",
      "Epoch 377/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.6160 - accuracy: 0.4474 - val_loss: 1.0661 - val_accuracy: 0.7296 - lr: 1.0000e-06\n",
      "Epoch 378/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 1.6210 - accuracy: 0.4349 - val_loss: 1.0596 - val_accuracy: 0.7348 - lr: 1.0000e-06\n",
      "Epoch 379/400\n",
      "312/312 [==============================] - 5s 17ms/step - loss: 1.5991 - accuracy: 0.4439 - val_loss: 1.0718 - val_accuracy: 0.7340 - lr: 1.0000e-06\n",
      "Epoch 380/400\n",
      "312/312 [==============================] - 6s 18ms/step - loss: 1.6062 - accuracy: 0.4385 - val_loss: 1.0539 - val_accuracy: 0.7368 - lr: 1.0000e-06\n",
      "Epoch 381/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5973 - accuracy: 0.4438 - val_loss: 1.0577 - val_accuracy: 0.7364 - lr: 1.0000e-06\n",
      "Epoch 382/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.5882 - accuracy: 0.4481 - val_loss: 1.0608 - val_accuracy: 0.7360 - lr: 1.0000e-06\n",
      "Epoch 383/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.5940 - accuracy: 0.4466 - val_loss: 1.0557 - val_accuracy: 0.7344 - lr: 1.0000e-06\n",
      "Epoch 384/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 1.5862 - accuracy: 0.4425 - val_loss: 1.0565 - val_accuracy: 0.7372 - lr: 1.0000e-06\n",
      "Epoch 385/400\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 1.5975 - accuracy: 0.4422 - val_loss: 1.0543 - val_accuracy: 0.7372 - lr: 1.0000e-06\n",
      "Epoch 386/400\n",
      "312/312 [==============================] - 7s 21ms/step - loss: 1.5935 - accuracy: 0.4411 - val_loss: 1.0485 - val_accuracy: 0.7412 - lr: 1.0000e-06\n",
      "Epoch 387/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 1.5817 - accuracy: 0.4573 - val_loss: 1.0489 - val_accuracy: 0.7408 - lr: 1.0000e-06\n",
      "Epoch 388/400\n",
      "312/312 [==============================] - 6s 21ms/step - loss: 1.5980 - accuracy: 0.4442 - val_loss: 1.0497 - val_accuracy: 0.7400 - lr: 1.0000e-06\n",
      "Epoch 389/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.6006 - accuracy: 0.4446 - val_loss: 1.0467 - val_accuracy: 0.7428 - lr: 1.0000e-06\n",
      "Epoch 390/400\n",
      "312/312 [==============================] - 6s 20ms/step - loss: 1.6046 - accuracy: 0.4412 - val_loss: 1.0488 - val_accuracy: 0.7396 - lr: 1.0000e-06\n",
      "Epoch 391/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5714 - accuracy: 0.4545 - val_loss: 1.0437 - val_accuracy: 0.7424 - lr: 1.0000e-06\n",
      "Epoch 392/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.6019 - accuracy: 0.4452 - val_loss: 1.0417 - val_accuracy: 0.7432 - lr: 1.0000e-06\n",
      "Epoch 393/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5586 - accuracy: 0.4561 - val_loss: 1.0391 - val_accuracy: 0.7432 - lr: 1.0000e-06\n",
      "Epoch 394/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5648 - accuracy: 0.4643 - val_loss: 1.0373 - val_accuracy: 0.7460 - lr: 1.0000e-06\n",
      "Epoch 395/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5799 - accuracy: 0.4524 - val_loss: 1.0422 - val_accuracy: 0.7428 - lr: 1.0000e-06\n",
      "Epoch 396/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5807 - accuracy: 0.4515 - val_loss: 1.0398 - val_accuracy: 0.7440 - lr: 1.0000e-06\n",
      "Epoch 397/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5767 - accuracy: 0.4569 - val_loss: 1.0359 - val_accuracy: 0.7432 - lr: 1.0000e-06\n",
      "Epoch 398/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5553 - accuracy: 0.4701 - val_loss: 1.0365 - val_accuracy: 0.7412 - lr: 1.0000e-06\n",
      "Epoch 399/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5556 - accuracy: 0.4608 - val_loss: 1.0314 - val_accuracy: 0.7464 - lr: 1.0000e-06\n",
      "Epoch 400/400\n",
      "312/312 [==============================] - 6s 19ms/step - loss: 1.5733 - accuracy: 0.4579 - val_loss: 1.0316 - val_accuracy: 0.7444 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features_2, train_labels_2,epochs=400, batch_size=32, validation_data=(val_features_2, val_labels_2),callbacks=[early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "#Get features dataset 3/4\n",
    "train_features_3, train_labels_3 = get_features_and_labels(train_dataset_3)\n",
    "val_features_3, val_labels_3 = get_features_and_labels(validation_dataset_3)\n",
    "#test_features_3, test_labels_3 = get_features_and_labels(test_dataset_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "312/312 [==============================] - 4s 9ms/step - loss: 0.6896 - accuracy: 0.8031 - val_loss: 0.3883 - val_accuracy: 0.8670\n",
      "Epoch 2/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5400 - accuracy: 0.8407 - val_loss: 0.3926 - val_accuracy: 0.8694\n",
      "Epoch 3/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4832 - accuracy: 0.8564 - val_loss: 0.3953 - val_accuracy: 0.8714\n",
      "Epoch 4/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4006 - accuracy: 0.8822 - val_loss: 0.4186 - val_accuracy: 0.8690\n",
      "Epoch 5/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.3601 - accuracy: 0.8969 - val_loss: 0.4346 - val_accuracy: 0.8698\n",
      "Epoch 6/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.3169 - accuracy: 0.9059 - val_loss: 0.4620 - val_accuracy: 0.8666\n",
      "Epoch 7/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2910 - accuracy: 0.9161 - val_loss: 0.4974 - val_accuracy: 0.8598\n",
      "Epoch 8/300\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.2690 - accuracy: 0.9205 - val_loss: 0.5165 - val_accuracy: 0.8654\n",
      "Epoch 9/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.2464 - accuracy: 0.9281 - val_loss: 0.5433 - val_accuracy: 0.8626\n",
      "Epoch 10/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.2518 - accuracy: 0.9258 - val_loss: 0.5087 - val_accuracy: 0.8638\n",
      "Epoch 11/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2329 - accuracy: 0.9288 - val_loss: 0.5345 - val_accuracy: 0.8558\n",
      "Epoch 12/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2156 - accuracy: 0.9367 - val_loss: 0.5744 - val_accuracy: 0.8518\n",
      "Epoch 13/300\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.2053 - accuracy: 0.9393 - val_loss: 0.5997 - val_accuracy: 0.8554\n",
      "Epoch 14/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1844 - accuracy: 0.9469 - val_loss: 0.5698 - val_accuracy: 0.8634\n",
      "Epoch 15/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1871 - accuracy: 0.9442 - val_loss: 0.5887 - val_accuracy: 0.8622\n",
      "Epoch 16/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1871 - accuracy: 0.9450 - val_loss: 0.6281 - val_accuracy: 0.8530\n",
      "Epoch 17/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1499 - accuracy: 0.9537 - val_loss: 0.6145 - val_accuracy: 0.8622\n",
      "Epoch 18/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1638 - accuracy: 0.9531 - val_loss: 0.6036 - val_accuracy: 0.8578\n",
      "Epoch 19/300\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1594 - accuracy: 0.9520 - val_loss: 0.6306 - val_accuracy: 0.8614\n",
      "Epoch 20/300\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1637 - accuracy: 0.9509 - val_loss: 0.5991 - val_accuracy: 0.8550\n",
      "Epoch 21/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1554 - accuracy: 0.9557 - val_loss: 0.6024 - val_accuracy: 0.8598\n",
      "Epoch 22/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1502 - accuracy: 0.9565 - val_loss: 0.6088 - val_accuracy: 0.8598\n",
      "Epoch 23/300\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1440 - accuracy: 0.9575 - val_loss: 0.6307 - val_accuracy: 0.8622\n",
      "Epoch 24/300\n",
      " 84/312 [=======>......................] - ETA: 2s - loss: 0.1513 - accuracy: 0.9542"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_features_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train_features_3, train_labels_3,epochs=300, batch_size=32, validation_data=(val_features_3, val_labels_3),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "train_features_4, train_labels_4 = get_features_and_labels(train_dataset_4)\n",
    "val_features_4, val_labels_4 = get_features_and_labels(validation_dataset_4)\n",
    "#test_features_4, test_labels_4 = get_features_and_labels(test_dataset_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "312/312 [==============================] - 9s 26ms/step - loss: 2.9612 - accuracy: 0.1868 - val_loss: 1.6261 - val_accuracy: 0.4671 - lr: 1.0000e-05\n",
      "Epoch 2/200\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 2.1638 - accuracy: 0.3357 - val_loss: 1.2137 - val_accuracy: 0.6114 - lr: 1.0000e-05\n",
      "Epoch 3/200\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 1.7042 - accuracy: 0.4551 - val_loss: 1.0084 - val_accuracy: 0.6843 - lr: 1.0000e-05\n",
      "Epoch 4/200\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 1.4529 - accuracy: 0.5344 - val_loss: 0.8840 - val_accuracy: 0.7196 - lr: 1.0000e-05\n",
      "Epoch 5/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 1.2578 - accuracy: 0.5890 - val_loss: 0.8014 - val_accuracy: 0.7464 - lr: 1.0000e-05\n",
      "Epoch 6/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 1.1623 - accuracy: 0.6218 - val_loss: 0.7447 - val_accuracy: 0.7636 - lr: 1.0000e-05\n",
      "Epoch 7/200\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 1.0415 - accuracy: 0.6589 - val_loss: 0.7068 - val_accuracy: 0.7736 - lr: 1.0000e-05\n",
      "Epoch 8/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.9552 - accuracy: 0.6880 - val_loss: 0.6692 - val_accuracy: 0.7877 - lr: 1.0000e-05\n",
      "Epoch 9/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.9143 - accuracy: 0.7038 - val_loss: 0.6392 - val_accuracy: 0.7953 - lr: 1.0000e-05\n",
      "Epoch 10/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.8526 - accuracy: 0.7269 - val_loss: 0.6178 - val_accuracy: 0.8017 - lr: 1.0000e-05\n",
      "Epoch 11/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.7953 - accuracy: 0.7402 - val_loss: 0.5933 - val_accuracy: 0.8085 - lr: 1.0000e-05\n",
      "Epoch 12/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.7585 - accuracy: 0.7525 - val_loss: 0.5776 - val_accuracy: 0.8149 - lr: 1.0000e-05\n",
      "Epoch 13/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.7330 - accuracy: 0.7573 - val_loss: 0.5614 - val_accuracy: 0.8169 - lr: 1.0000e-05\n",
      "Epoch 14/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.6950 - accuracy: 0.7729 - val_loss: 0.5501 - val_accuracy: 0.8221 - lr: 1.0000e-05\n",
      "Epoch 15/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.6609 - accuracy: 0.7827 - val_loss: 0.5354 - val_accuracy: 0.8293 - lr: 1.0000e-05\n",
      "Epoch 16/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.6471 - accuracy: 0.7881 - val_loss: 0.5260 - val_accuracy: 0.8309 - lr: 1.0000e-05\n",
      "Epoch 17/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.6067 - accuracy: 0.8063 - val_loss: 0.5157 - val_accuracy: 0.8345 - lr: 1.0000e-05\n",
      "Epoch 18/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.5987 - accuracy: 0.8014 - val_loss: 0.5083 - val_accuracy: 0.8373 - lr: 1.0000e-05\n",
      "Epoch 19/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.5519 - accuracy: 0.8180 - val_loss: 0.5032 - val_accuracy: 0.8373 - lr: 1.0000e-05\n",
      "Epoch 20/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.5487 - accuracy: 0.8216 - val_loss: 0.4976 - val_accuracy: 0.8417 - lr: 1.0000e-05\n",
      "Epoch 21/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.5286 - accuracy: 0.8275 - val_loss: 0.4891 - val_accuracy: 0.8446 - lr: 1.0000e-05\n",
      "Epoch 22/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.4999 - accuracy: 0.8374 - val_loss: 0.4834 - val_accuracy: 0.8478 - lr: 1.0000e-05\n",
      "Epoch 23/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.4898 - accuracy: 0.8412 - val_loss: 0.4806 - val_accuracy: 0.8466 - lr: 1.0000e-05\n",
      "Epoch 24/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.4735 - accuracy: 0.8429 - val_loss: 0.4756 - val_accuracy: 0.8498 - lr: 1.0000e-05\n",
      "Epoch 25/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.4612 - accuracy: 0.8492 - val_loss: 0.4693 - val_accuracy: 0.8502 - lr: 1.0000e-05\n",
      "Epoch 26/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.4356 - accuracy: 0.8597 - val_loss: 0.4671 - val_accuracy: 0.8494 - lr: 1.0000e-05\n",
      "Epoch 27/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.4256 - accuracy: 0.8609 - val_loss: 0.4660 - val_accuracy: 0.8510 - lr: 1.0000e-05\n",
      "Epoch 28/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.4212 - accuracy: 0.8657 - val_loss: 0.4607 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Epoch 29/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3957 - accuracy: 0.8722 - val_loss: 0.4563 - val_accuracy: 0.8514 - lr: 1.0000e-05\n",
      "Epoch 30/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3814 - accuracy: 0.8742 - val_loss: 0.4542 - val_accuracy: 0.8522 - lr: 1.0000e-05\n",
      "Epoch 31/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3804 - accuracy: 0.8759 - val_loss: 0.4509 - val_accuracy: 0.8534 - lr: 1.0000e-05\n",
      "Epoch 32/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3669 - accuracy: 0.8827 - val_loss: 0.4503 - val_accuracy: 0.8534 - lr: 1.0000e-05\n",
      "Epoch 33/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3645 - accuracy: 0.8827 - val_loss: 0.4477 - val_accuracy: 0.8530 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3501 - accuracy: 0.8861 - val_loss: 0.4469 - val_accuracy: 0.8538 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.3329 - accuracy: 0.8897 - val_loss: 0.4441 - val_accuracy: 0.8554 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.3149 - accuracy: 0.8966 - val_loss: 0.4423 - val_accuracy: 0.8542 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "312/312 [==============================] - 9s 29ms/step - loss: 0.3060 - accuracy: 0.9004 - val_loss: 0.4431 - val_accuracy: 0.8542 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "312/312 [==============================] - 12s 38ms/step - loss: 0.2960 - accuracy: 0.9047 - val_loss: 0.4407 - val_accuracy: 0.8558 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 0.2860 - accuracy: 0.9084 - val_loss: 0.4391 - val_accuracy: 0.8554 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "312/312 [==============================] - 10s 32ms/step - loss: 0.2785 - accuracy: 0.9115 - val_loss: 0.4364 - val_accuracy: 0.8574 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "312/312 [==============================] - 9s 29ms/step - loss: 0.2702 - accuracy: 0.9116 - val_loss: 0.4364 - val_accuracy: 0.8566 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.2751 - accuracy: 0.9133 - val_loss: 0.4348 - val_accuracy: 0.8582 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.2644 - accuracy: 0.9152 - val_loss: 0.4363 - val_accuracy: 0.8590 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.2481 - accuracy: 0.9218 - val_loss: 0.4358 - val_accuracy: 0.8582 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.2427 - accuracy: 0.9241 - val_loss: 0.4356 - val_accuracy: 0.8586 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.2382 - accuracy: 0.9231 - val_loss: 0.4346 - val_accuracy: 0.8614 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.2373 - accuracy: 0.9238 - val_loss: 0.4368 - val_accuracy: 0.8574 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.2173 - accuracy: 0.9339 - val_loss: 0.4375 - val_accuracy: 0.8586 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.2231 - accuracy: 0.9290 - val_loss: 0.4370 - val_accuracy: 0.8602 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.2185 - accuracy: 0.9330 - val_loss: 0.4409 - val_accuracy: 0.8578 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1994 - accuracy: 0.9400 - val_loss: 0.4368 - val_accuracy: 0.8618 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1893 - accuracy: 0.9442 - val_loss: 0.4369 - val_accuracy: 0.8626 - lr: 2.0000e-06\n",
      "Epoch 53/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1941 - accuracy: 0.9417 - val_loss: 0.4375 - val_accuracy: 0.8606 - lr: 2.0000e-06\n",
      "Epoch 54/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.1948 - accuracy: 0.9399 - val_loss: 0.4369 - val_accuracy: 0.8606 - lr: 2.0000e-06\n",
      "Epoch 55/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1890 - accuracy: 0.9417 - val_loss: 0.4372 - val_accuracy: 0.8622 - lr: 2.0000e-06\n",
      "Epoch 56/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1928 - accuracy: 0.9409 - val_loss: 0.4366 - val_accuracy: 0.8626 - lr: 2.0000e-06\n",
      "Epoch 57/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1894 - accuracy: 0.9407 - val_loss: 0.4361 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 58/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.1851 - accuracy: 0.9424 - val_loss: 0.4367 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 59/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1915 - accuracy: 0.9388 - val_loss: 0.4369 - val_accuracy: 0.8622 - lr: 1.0000e-06\n",
      "Epoch 60/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1812 - accuracy: 0.9433 - val_loss: 0.4368 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 61/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1825 - accuracy: 0.9446 - val_loss: 0.4367 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 62/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1874 - accuracy: 0.9421 - val_loss: 0.4376 - val_accuracy: 0.8622 - lr: 1.0000e-06\n",
      "Epoch 63/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1846 - accuracy: 0.9421 - val_loss: 0.4381 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 64/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1893 - accuracy: 0.9415 - val_loss: 0.4359 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 65/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1918 - accuracy: 0.9399 - val_loss: 0.4378 - val_accuracy: 0.8626 - lr: 1.0000e-06\n",
      "Epoch 66/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1827 - accuracy: 0.9470 - val_loss: 0.4360 - val_accuracy: 0.8642 - lr: 1.0000e-06\n",
      "Epoch 67/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1845 - accuracy: 0.9457 - val_loss: 0.4376 - val_accuracy: 0.8626 - lr: 1.0000e-06\n",
      "Epoch 68/200\n",
      "312/312 [==============================] - 8s 26ms/step - loss: 0.1794 - accuracy: 0.9476 - val_loss: 0.4367 - val_accuracy: 0.8626 - lr: 1.0000e-06\n",
      "Epoch 69/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1790 - accuracy: 0.9450 - val_loss: 0.4386 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 70/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1839 - accuracy: 0.9462 - val_loss: 0.4362 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 71/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1843 - accuracy: 0.9441 - val_loss: 0.4376 - val_accuracy: 0.8622 - lr: 1.0000e-06\n",
      "Epoch 72/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1766 - accuracy: 0.9479 - val_loss: 0.4377 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 73/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1850 - accuracy: 0.9446 - val_loss: 0.4380 - val_accuracy: 0.8626 - lr: 1.0000e-06\n",
      "Epoch 74/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1786 - accuracy: 0.9460 - val_loss: 0.4369 - val_accuracy: 0.8642 - lr: 1.0000e-06\n",
      "Epoch 75/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1814 - accuracy: 0.9456 - val_loss: 0.4376 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 76/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.1836 - accuracy: 0.9450 - val_loss: 0.4382 - val_accuracy: 0.8638 - lr: 1.0000e-06\n",
      "Epoch 77/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1828 - accuracy: 0.9448 - val_loss: 0.4372 - val_accuracy: 0.8662 - lr: 1.0000e-06\n",
      "Epoch 78/200\n",
      "312/312 [==============================] - 8s 27ms/step - loss: 0.1744 - accuracy: 0.9480 - val_loss: 0.4376 - val_accuracy: 0.8650 - lr: 1.0000e-06\n",
      "Epoch 79/200\n",
      "312/312 [==============================] - 9s 27ms/step - loss: 0.1740 - accuracy: 0.9472 - val_loss: 0.4370 - val_accuracy: 0.8638 - lr: 1.0000e-06\n",
      "Epoch 80/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1818 - accuracy: 0.9471 - val_loss: 0.4388 - val_accuracy: 0.8618 - lr: 1.0000e-06\n",
      "Epoch 81/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1784 - accuracy: 0.9440 - val_loss: 0.4382 - val_accuracy: 0.8618 - lr: 1.0000e-06\n",
      "Epoch 82/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1742 - accuracy: 0.9485 - val_loss: 0.4381 - val_accuracy: 0.8626 - lr: 1.0000e-06\n",
      "Epoch 83/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1799 - accuracy: 0.9450 - val_loss: 0.4386 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 84/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1685 - accuracy: 0.9475 - val_loss: 0.4374 - val_accuracy: 0.8650 - lr: 1.0000e-06\n",
      "Epoch 85/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1728 - accuracy: 0.9479 - val_loss: 0.4391 - val_accuracy: 0.8638 - lr: 1.0000e-06\n",
      "Epoch 86/200\n",
      "312/312 [==============================] - 9s 28ms/step - loss: 0.1668 - accuracy: 0.9505 - val_loss: 0.4370 - val_accuracy: 0.8618 - lr: 1.0000e-06\n",
      "Epoch 87/200\n",
      "312/312 [==============================] - 9s 29ms/step - loss: 0.1727 - accuracy: 0.9475 - val_loss: 0.4386 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 88/200\n",
      "312/312 [==============================] - 9s 29ms/step - loss: 0.1742 - accuracy: 0.9470 - val_loss: 0.4385 - val_accuracy: 0.8638 - lr: 1.0000e-06\n",
      "Epoch 89/200\n",
      "312/312 [==============================] - 10s 31ms/step - loss: 0.1736 - accuracy: 0.9481 - val_loss: 0.4368 - val_accuracy: 0.8634 - lr: 1.0000e-06\n",
      "Epoch 90/200\n",
      "312/312 [==============================] - 11s 36ms/step - loss: 0.1649 - accuracy: 0.9504 - val_loss: 0.4378 - val_accuracy: 0.8630 - lr: 1.0000e-06\n",
      "Epoch 91/200\n",
      "312/312 [==============================] - 11s 34ms/step - loss: 0.1742 - accuracy: 0.9483 - val_loss: 0.4377 - val_accuracy: 0.8638 - lr: 1.0000e-06\n",
      "Epoch 92/200\n",
      "124/312 [==========>...................] - ETA: 5s - loss: 0.1666 - accuracy: 0.9549"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Baixamos o lerning rate para tentar chegar aos 0.9 de val_accuracy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Adicionamos os weight_decay para regolarização, também para combater o overfiting\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-6, weight_decay=1e-3),metrics=['accuracy'])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#history = model.fit(train_features_1, train_labels_1,epochs=400, batch_size=32, validation_data=(val_features_1, val_labels_1),callbacks=[early_stopping,reduce_lr])\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#history = model.fit(train_features_2, train_labels_2,epochs=400, batch_size=32, validation_data=(val_features_2, val_labels_2),callbacks=[early_stopping,reduce_lr])\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_features_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#history = model.fit(train_features_4, train_labels_4,epochs=400, batch_size=32, validation_data=(val_features_4, val_labels_4),callbacks=[early_stopping,reduce_lr])\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Baixamos o lerning rate para tentar chegar aos 0.9 de val_accuracy\n",
    "#Adicionamos os weight_decay para regolarização, também para combater o overfiting\n",
    "#model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-6, weight_decay=1e-3),metrics=['accuracy'])\n",
    "\n",
    "#history = model.fit(train_features_1, train_labels_1,epochs=400, batch_size=32, validation_data=(val_features_1, val_labels_1),callbacks=[early_stopping,reduce_lr])\n",
    "#history = model.fit(train_features_2, train_labels_2,epochs=400, batch_size=32, validation_data=(val_features_2, val_labels_2),callbacks=[early_stopping,reduce_lr])\n",
    "history = model.fit(train_features_3, train_labels_3,epochs=200, batch_size=32, validation_data=(val_features_3, val_labels_3),callbacks=[early_stopping,reduce_lr])\n",
    "#history = model.fit(train_features_4, train_labels_4,epochs=400, batch_size=32, validation_data=(val_features_4, val_labels_4),callbacks=[early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "312/312 [==============================] - 4s 9ms/step - loss: 0.5290 - accuracy: 0.8320 - val_loss: 0.4220 - val_accuracy: 0.8642\n",
      "Epoch 2/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.5138 - accuracy: 0.8364 - val_loss: 0.4177 - val_accuracy: 0.8686\n",
      "Epoch 3/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.4906 - accuracy: 0.8464 - val_loss: 0.4121 - val_accuracy: 0.8710\n",
      "Epoch 4/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4770 - accuracy: 0.8512 - val_loss: 0.4084 - val_accuracy: 0.8722\n",
      "Epoch 5/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4566 - accuracy: 0.8550 - val_loss: 0.4049 - val_accuracy: 0.8718\n",
      "Epoch 6/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.4430 - accuracy: 0.8613 - val_loss: 0.4011 - val_accuracy: 0.8750\n",
      "Epoch 7/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4286 - accuracy: 0.8668 - val_loss: 0.3993 - val_accuracy: 0.8746\n",
      "Epoch 8/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.4042 - accuracy: 0.8760 - val_loss: 0.3962 - val_accuracy: 0.8742\n",
      "Epoch 9/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3936 - accuracy: 0.8835 - val_loss: 0.3928 - val_accuracy: 0.8774\n",
      "Epoch 10/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3830 - accuracy: 0.8830 - val_loss: 0.3917 - val_accuracy: 0.8798\n",
      "Epoch 11/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.3786 - accuracy: 0.8820 - val_loss: 0.3882 - val_accuracy: 0.8782\n",
      "Epoch 12/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.3620 - accuracy: 0.8904 - val_loss: 0.3865 - val_accuracy: 0.8786\n",
      "Epoch 13/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3466 - accuracy: 0.8975 - val_loss: 0.3854 - val_accuracy: 0.8786\n",
      "Epoch 14/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.3311 - accuracy: 0.8996 - val_loss: 0.3841 - val_accuracy: 0.8786\n",
      "Epoch 15/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3286 - accuracy: 0.9042 - val_loss: 0.3824 - val_accuracy: 0.8790\n",
      "Epoch 16/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3136 - accuracy: 0.9078 - val_loss: 0.3804 - val_accuracy: 0.8802\n",
      "Epoch 17/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.3015 - accuracy: 0.9132 - val_loss: 0.3799 - val_accuracy: 0.8802\n",
      "Epoch 18/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2943 - accuracy: 0.9157 - val_loss: 0.3800 - val_accuracy: 0.8810\n",
      "Epoch 19/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2748 - accuracy: 0.9247 - val_loss: 0.3777 - val_accuracy: 0.8802\n",
      "Epoch 20/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2691 - accuracy: 0.9264 - val_loss: 0.3758 - val_accuracy: 0.8798\n",
      "Epoch 21/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2565 - accuracy: 0.9323 - val_loss: 0.3744 - val_accuracy: 0.8822\n",
      "Epoch 22/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2499 - accuracy: 0.9351 - val_loss: 0.3758 - val_accuracy: 0.8810\n",
      "Epoch 23/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2467 - accuracy: 0.9333 - val_loss: 0.3759 - val_accuracy: 0.8822\n",
      "Epoch 24/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2389 - accuracy: 0.9392 - val_loss: 0.3743 - val_accuracy: 0.8786\n",
      "Epoch 25/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2275 - accuracy: 0.9404 - val_loss: 0.3735 - val_accuracy: 0.8794\n",
      "Epoch 26/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.2215 - accuracy: 0.9433 - val_loss: 0.3729 - val_accuracy: 0.8802\n",
      "Epoch 27/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.2162 - accuracy: 0.9436 - val_loss: 0.3727 - val_accuracy: 0.8798\n",
      "Epoch 28/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.2021 - accuracy: 0.9523 - val_loss: 0.3728 - val_accuracy: 0.8802\n",
      "Epoch 29/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1982 - accuracy: 0.9516 - val_loss: 0.3725 - val_accuracy: 0.8786\n",
      "Epoch 30/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1958 - accuracy: 0.9509 - val_loss: 0.3726 - val_accuracy: 0.8790\n",
      "Epoch 31/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.1885 - accuracy: 0.9546 - val_loss: 0.3731 - val_accuracy: 0.8782\n",
      "Epoch 32/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1810 - accuracy: 0.9557 - val_loss: 0.3731 - val_accuracy: 0.8774\n",
      "Epoch 33/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1736 - accuracy: 0.9616 - val_loss: 0.3716 - val_accuracy: 0.8794\n",
      "Epoch 34/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1730 - accuracy: 0.9601 - val_loss: 0.3729 - val_accuracy: 0.8786\n",
      "Epoch 35/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1588 - accuracy: 0.9641 - val_loss: 0.3724 - val_accuracy: 0.8790\n",
      "Epoch 36/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1581 - accuracy: 0.9640 - val_loss: 0.3729 - val_accuracy: 0.8790\n",
      "Epoch 37/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1544 - accuracy: 0.9660 - val_loss: 0.3755 - val_accuracy: 0.8802\n",
      "Epoch 38/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1469 - accuracy: 0.9676 - val_loss: 0.3761 - val_accuracy: 0.8790\n",
      "Epoch 39/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1425 - accuracy: 0.9696 - val_loss: 0.3760 - val_accuracy: 0.8786\n",
      "Epoch 40/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1376 - accuracy: 0.9702 - val_loss: 0.3766 - val_accuracy: 0.8790\n",
      "Epoch 41/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1331 - accuracy: 0.9711 - val_loss: 0.3763 - val_accuracy: 0.8766\n",
      "Epoch 42/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.1293 - accuracy: 0.9744 - val_loss: 0.3760 - val_accuracy: 0.8766\n",
      "Epoch 43/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.1228 - accuracy: 0.9784 - val_loss: 0.3779 - val_accuracy: 0.8790\n",
      "Epoch 44/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.1239 - accuracy: 0.9737 - val_loss: 0.3784 - val_accuracy: 0.8762\n",
      "Epoch 45/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.1186 - accuracy: 0.9766 - val_loss: 0.3792 - val_accuracy: 0.8802\n",
      "Epoch 46/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.1119 - accuracy: 0.9806 - val_loss: 0.3785 - val_accuracy: 0.8810\n",
      "Epoch 47/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1059 - accuracy: 0.9798 - val_loss: 0.3798 - val_accuracy: 0.8782\n",
      "Epoch 48/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1047 - accuracy: 0.9802 - val_loss: 0.3804 - val_accuracy: 0.8786\n",
      "Epoch 49/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.1006 - accuracy: 0.9819 - val_loss: 0.3805 - val_accuracy: 0.8778\n",
      "Epoch 50/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0996 - accuracy: 0.9808 - val_loss: 0.3808 - val_accuracy: 0.8798\n",
      "Epoch 51/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0922 - accuracy: 0.9830 - val_loss: 0.3820 - val_accuracy: 0.8782\n",
      "Epoch 52/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0922 - accuracy: 0.9835 - val_loss: 0.3824 - val_accuracy: 0.8762\n",
      "Epoch 53/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.0933 - accuracy: 0.9828 - val_loss: 0.3846 - val_accuracy: 0.8754\n",
      "Epoch 54/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0870 - accuracy: 0.9855 - val_loss: 0.3844 - val_accuracy: 0.8762\n",
      "Epoch 55/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0853 - accuracy: 0.9852 - val_loss: 0.3846 - val_accuracy: 0.8762\n",
      "Epoch 56/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0814 - accuracy: 0.9851 - val_loss: 0.3846 - val_accuracy: 0.8738\n",
      "Epoch 57/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0815 - accuracy: 0.9858 - val_loss: 0.3872 - val_accuracy: 0.8762\n",
      "Epoch 58/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0763 - accuracy: 0.9868 - val_loss: 0.3872 - val_accuracy: 0.8794\n",
      "Epoch 59/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0730 - accuracy: 0.9887 - val_loss: 0.3878 - val_accuracy: 0.8790\n",
      "Epoch 60/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0738 - accuracy: 0.9868 - val_loss: 0.3868 - val_accuracy: 0.8790\n",
      "Epoch 61/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0688 - accuracy: 0.9897 - val_loss: 0.3888 - val_accuracy: 0.8790\n",
      "Epoch 62/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.0677 - accuracy: 0.9882 - val_loss: 0.3885 - val_accuracy: 0.8810\n",
      "Epoch 63/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0644 - accuracy: 0.9912 - val_loss: 0.3903 - val_accuracy: 0.8794\n",
      "Epoch 64/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0651 - accuracy: 0.9908 - val_loss: 0.3907 - val_accuracy: 0.8786\n",
      "Epoch 65/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0615 - accuracy: 0.9913 - val_loss: 0.3911 - val_accuracy: 0.8810\n",
      "Epoch 66/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0594 - accuracy: 0.9916 - val_loss: 0.3919 - val_accuracy: 0.8798\n",
      "Epoch 67/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0601 - accuracy: 0.9905 - val_loss: 0.3925 - val_accuracy: 0.8830\n",
      "Epoch 68/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0587 - accuracy: 0.9914 - val_loss: 0.3945 - val_accuracy: 0.8802\n",
      "Epoch 69/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0561 - accuracy: 0.9916 - val_loss: 0.3955 - val_accuracy: 0.8818\n",
      "Epoch 70/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0538 - accuracy: 0.9923 - val_loss: 0.3946 - val_accuracy: 0.8810\n",
      "Epoch 71/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.0523 - accuracy: 0.9926 - val_loss: 0.3962 - val_accuracy: 0.8814\n",
      "Epoch 72/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0502 - accuracy: 0.9937 - val_loss: 0.3958 - val_accuracy: 0.8818\n",
      "Epoch 73/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0500 - accuracy: 0.9926 - val_loss: 0.3987 - val_accuracy: 0.8818\n",
      "Epoch 74/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0484 - accuracy: 0.9928 - val_loss: 0.4007 - val_accuracy: 0.8786\n",
      "Epoch 75/80\n",
      "312/312 [==============================] - 3s 8ms/step - loss: 0.0453 - accuracy: 0.9941 - val_loss: 0.4023 - val_accuracy: 0.8798\n",
      "Epoch 76/80\n",
      "312/312 [==============================] - 2s 8ms/step - loss: 0.0482 - accuracy: 0.9934 - val_loss: 0.4038 - val_accuracy: 0.8778\n",
      "Epoch 77/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.0457 - accuracy: 0.9945 - val_loss: 0.4030 - val_accuracy: 0.8802\n",
      "Epoch 78/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.0414 - accuracy: 0.9954 - val_loss: 0.4043 - val_accuracy: 0.8802\n",
      "Epoch 79/80\n",
      "312/312 [==============================] - 3s 9ms/step - loss: 0.0410 - accuracy: 0.9952 - val_loss: 0.4051 - val_accuracy: 0.8786\n",
      "Epoch 80/80\n",
      "312/312 [==============================] - 2s 7ms/step - loss: 0.0410 - accuracy: 0.9956 - val_loss: 0.4071 - val_accuracy: 0.8778\n"
     ]
    }
   ],
   "source": [
    "#testes\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-6, weight_decay=1e-2),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_features_2, train_labels_2,epochs=80, batch_size=32, validation_data=(val_features_2, val_labels_2),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar o modelo\n",
    "from keras import models\n",
    "inputs = keras.Input(shape=(150, 150, 3))\n",
    "x = keras.applications.vgg19.preprocess_input(inputs) \n",
    "x = conv_base(x)\n",
    "outputs = model(x)\n",
    "full_model = keras.Model(inputs, outputs)\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-6, weight_decay=1e-4),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "full_model.save('ModelT_transferLearning_featureExtraction_WithoutDataAumentation.h5')\n",
    "model.save('ModelT_transferLearning_featureExtraction_WithoutDataAumentation_OnlyClassification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "312/312 [==============================] - 11s 32ms/step - loss: 7.5088 - accuracy: 0.5365 - val_loss: 7.3419 - val_accuracy: 0.6206\n",
      "Epoch 2/120\n",
      "312/312 [==============================] - 10s 33ms/step - loss: 7.4937 - accuracy: 0.5378 - val_loss: 7.3027 - val_accuracy: 0.6234\n",
      "Epoch 3/120\n",
      " 87/312 [=======>......................] - ETA: 7s - loss: 7.4733 - accuracy: 0.5456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m),metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_features_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels_1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tentar chegar a 0.9 de vall_acc\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=120, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.Adam(learning_rate=1e-6, weight_decay=1e-3),metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_features_1, train_labels_1,epochs=120, batch_size=32, validation_data=(val_features_1, val_labels_1), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 910s 3s/step - loss: 0.6878 - accuracy: 0.8901\n",
      "val_acc: 0.8901000022888184\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "loaded_model = keras.models.load_model('ModelT_transferLearning_featureExtraction_WithoutDataAumentation.h5')\n",
    "\n",
    "val_loss, val_acc = loaded_model.evaluate(validation_dataset) \n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 4, 4, 512)]       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               4194816   \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4201994 (16.03 MB)\n",
      "Trainable params: 4200970 (16.03 MB)\n",
      "Non-trainable params: 1024 (4.00 KB)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Optimizer: <keras.src.optimizers.adam.Adam object at 0x17264ded0>\n",
      "Loss function: <function categorical_crossentropy at 0x133c4fd80>\n",
      "Metrics: [<keras.src.metrics.base_metric.Mean object at 0x172587e10>, <keras.src.metrics.base_metric.MeanMetricWrapper object at 0x1729ee410>]\n"
     ]
    }
   ],
   "source": [
    "# Assuming loaded_model is the variable containing your model\n",
    "print(loaded_model.get_layer('model_1').summary())\n",
    "print(\"Optimizer:\", loaded_model.optimizer)\n",
    "print(\"Loss function:\", loaded_model.loss)\n",
    "print(\"Metrics:\", loaded_model.metrics)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
